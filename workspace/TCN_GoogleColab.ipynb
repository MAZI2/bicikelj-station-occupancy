{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hLYjcJez30x7"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAOCxvlcZnyv",
        "outputId": "4a21adec-f8ec-4fab-f946-55b52a1859d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "import random\n",
        "\n",
        "# --- Static Params ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "EPOCHS = 20\n",
        "PATIENCE = 5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_COMBINATIONS = 20\n",
        "TRAIN_FRACTION = 0.01\n",
        "EMBED_DIM = 8\n",
        "\n",
        "# --- Load data ---\n",
        "df = pd.read_csv('bicikelj_train.csv')\n",
        "meta = pd.read_csv('bicikelj_metadata.csv')\n",
        "station_cols = df.columns[1:]\n",
        "\n",
        "# Clean and fill\n",
        "for col in station_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df[station_cols] = df[station_cols].ffill().bfill()\n",
        "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
        "\n",
        "# --- Station normalization ---\n",
        "station_means = df[station_cols].mean()\n",
        "station_stds = df[station_cols].std().replace(0, 1)\n",
        "df_norm = df.copy()\n",
        "df_norm[station_cols] = (df[station_cols] - station_means) / station_stds\n",
        "\n",
        "# --- Neighbors ---\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "station_names = meta['name'].tolist()\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- Dataset ---\n",
        "class SharedTCNDataset(Dataset):\n",
        "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon):\n",
        "        self.samples = []\n",
        "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "        timestamps = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
        "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "        slo_holidays = holidays.Slovenia()\n",
        "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "        time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                               month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "        bikes = df[station_cols].values.astype(np.float32)\n",
        "        N = len(df)\n",
        "\n",
        "        for s_name in station_cols:\n",
        "            s_idx = self.station_to_idx[s_name]\n",
        "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
        "            series = bikes[:, [s_idx] + nn_idx]\n",
        "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
        "\n",
        "            for i in range(history_len, N - pred_horizon + 1):\n",
        "                x = full_feats[i - history_len:i]\n",
        "                y = bikes[i:i + pred_horizon, s_idx]\n",
        "                self.samples.append((x, y, s_idx))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, sid = self.samples[idx]\n",
        "        return (torch.tensor(x, dtype=torch.float32),\n",
        "                torch.tensor(y, dtype=torch.float32),\n",
        "                torch.tensor(sid, dtype=torch.long))\n",
        "\n",
        "# --- TCN block ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]  # crop end\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        # x: [B, T, D] â†’ [B, D, T]\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]  # [B, C]\n",
        "        emb = self.embedding(station_id)  # [B, E]\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# --- Training ---\n",
        "def train_tcn(model, train_loader, val_loader, lr, weight_decay):\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.MSELoss()\n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for xb, yb, sid in train_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb, sid), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, sid in val_loader:\n",
        "                xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "                val_loss += criterion(model(xb, sid), yb).item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model, best_loss\n",
        "\n",
        "# --- Grid search ---\n",
        "param_grid = {\n",
        "    # 'hidden_dim': [32, 64, 128],\n",
        "    # 'dropout': [0.0, 0.1, 0.2],\n",
        "    # 'lr': [1e-3, 5e-4, 2e-4],\n",
        "    # 'weight_decay': [0.0, 1e-5, 1e-4]\n",
        "    'hidden_dim': [64],\n",
        "    'dropout': [0.2],\n",
        "    'lr': [0.0005],\n",
        "    'weight_decay': [0.0001]\n",
        "}\n",
        "param_combos = list(itertools.product(*param_grid.values()))\n",
        "random.shuffle(param_combos)\n",
        "param_combos = param_combos[:MAX_COMBINATIONS]\n",
        "\n",
        "# --- Dataset ---\n",
        "dataset = SharedTCNDataset(df_norm, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON)\n",
        "N = len(dataset)\n",
        "reduced_N = int(N * TRAIN_FRACTION)\n",
        "indices = list(range(N))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_size = int(reduced_N * 0.7)\n",
        "val_size = int(reduced_N * 0.15)\n",
        "holdout_size = reduced_N - train_size - val_size\n",
        "\n",
        "train_set = Subset(dataset, indices[:train_size])\n",
        "val_set = Subset(dataset, indices[train_size:train_size + val_size])\n",
        "holdout_set = Subset(dataset, indices[train_size + val_size:train_size + val_size + holdout_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64)\n",
        "holdout_loader = DataLoader(holdout_set, batch_size=64)\n",
        "\n",
        "# --- Run ---\n",
        "input_dim = 1 + K_NEIGHBORS + 8  # station + neighbors + time features\n",
        "output_dim = PRED_HORIZON\n",
        "num_stations = len(station_cols)\n",
        "\n",
        "n_layers = 4\n",
        "\n",
        "results = []\n",
        "print(f\"â³ Running grid search over {len(param_combos)} combinations...\")\n",
        "for i, (hdim, dr, lr, wd) in enumerate(param_combos):\n",
        "    print(f\"\\nðŸ” Combo {i+1}: hidden_dim={hdim}, dropout={dr}, lr={lr}, weight_decay={wd}\")\n",
        "    model = TCN(input_size=input_dim,\n",
        "                output_size=output_dim,\n",
        "                #num_channels=[hdim] * 3,\n",
        "                num_channels=[hdim] * n_layers,\n",
        "\n",
        "                kernel_size=3,\n",
        "                dropout=dr,\n",
        "                num_stations=num_stations,\n",
        "                embed_dim=EMBED_DIM)\n",
        "    model, val_loss = train_tcn(model, train_loader, val_loader, lr, wd)\n",
        "\n",
        "    model.eval()\n",
        "    holdout_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, sid in holdout_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            holdout_loss += criterion(model(xb, sid), yb).item()\n",
        "    holdout_loss /= len(holdout_loader)\n",
        "\n",
        "    print(f\"âœ… Val Loss: {val_loss:.4f}, Holdout Loss: {holdout_loss:.4f}\")\n",
        "    results.append({\n",
        "        \"hidden_dim\": hdim,\n",
        "        \"dropout\": dr,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": wd,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"holdout_loss\": holdout_loss\n",
        "    })\n",
        "\n",
        "# --- Save ---\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"holdout_loss\")\n",
        "results_df.to_csv(\"grid_search_tcn_results.csv\", index=False)\n",
        "print(\"\\nðŸ“Š Top 5 Results:\")\n",
        "print(results_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63rRBlfydJaR",
        "outputId": "4183be6d-21ab-49ca-a78e-22d224f01047"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Running grid search over 1 combinations...\n",
            "\n",
            "ðŸ” Combo 1: hidden_dim=64, dropout=0.2, lr=0.0005, weight_decay=0.0001\n",
            "âœ… Val Loss: 0.3289, Holdout Loss: 0.3381\n",
            "\n",
            "ðŸ“Š Top 5 Results:\n",
            "   hidden_dim  dropout      lr  weight_decay  val_loss  holdout_loss\n",
            "0          64      0.2  0.0005        0.0001  0.328911      0.338051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete"
      ],
      "metadata": {
        "id": "AiUdIxZxiYK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TCN Bicikelj final training + test prediction with speedups ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "import random\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EMBED_DIM = 8\n",
        "HIDDEN_DIM = 64\n",
        "N_LAYERS = 3\n",
        "LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0001\n",
        "DROPOUT = 0.2\n",
        "EPOCHS = 50\n",
        "PATIENCE = 8\n",
        "BATCH_SIZE = 128  # increased safely\n",
        "\n",
        "# --- Load data ---\n",
        "df = pd.read_csv(\"bicikelj_train.csv\")\n",
        "meta = pd.read_csv(\"bicikelj_metadata.csv\")\n",
        "station_cols = df.columns[1:]\n",
        "\n",
        "# Clean and fill\n",
        "for col in station_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df[station_cols] = df[station_cols].ffill().bfill()\n",
        "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
        "\n",
        "# Station normalization\n",
        "station_means = df[station_cols].mean()\n",
        "station_stds = df[station_cols].std().replace(0, 1)\n",
        "df_norm = df.copy()\n",
        "df_norm[station_cols] = (df[station_cols] - station_means) / station_stds\n",
        "\n",
        "# Neighbors\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "station_names = meta['name'].tolist()\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- Dataset ---\n",
        "class SharedTCNDataset(Dataset):\n",
        "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon):\n",
        "        self.samples = []\n",
        "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "        timestamps = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "        slo_holidays = holidays.Slovenia()\n",
        "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "        time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                               month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "        bikes = df[station_cols].values.astype(np.float32)\n",
        "        N = len(df)\n",
        "\n",
        "        for s_name in station_cols:\n",
        "            s_idx = self.station_to_idx[s_name]\n",
        "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
        "            series = bikes[:, [s_idx] + nn_idx]\n",
        "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
        "\n",
        "            for i in range(history_len, N - pred_horizon + 1):\n",
        "                x = full_feats[i - history_len:i]\n",
        "                y = bikes[i:i + pred_horizon, s_idx]\n",
        "                self.samples.append((x, y, s_idx))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, sid = self.samples[idx]\n",
        "        return (torch.tensor(x, dtype=torch.float32),\n",
        "                torch.tensor(y, dtype=torch.float32),\n",
        "                torch.tensor(sid, dtype=torch.long))\n",
        "\n",
        "# --- TCN Block ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]\n",
        "        emb = self.embedding(station_id)\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# --- Create Dataset and split ---\n",
        "dataset = SharedTCNDataset(df_norm, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON)\n",
        "\n",
        "N = len(dataset)\n",
        "indices = list(range(N))\n",
        "random.shuffle(indices)\n",
        "\n",
        "val_size = int(0.1 * N)  # 10% for val\n",
        "train_size = N - val_size\n",
        "\n",
        "train_indices = indices[:train_size]\n",
        "val_indices = indices[train_size:]\n",
        "\n",
        "train_set = Subset(dataset, train_indices)\n",
        "val_set = Subset(dataset, val_indices)\n",
        "\n",
        "# --- DataLoaders with speedups ---\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
        "\n",
        "# --- Model ---\n",
        "model = TCN(input_size=1 + K_NEIGHBORS + 8,\n",
        "            output_size=PRED_HORIZON,\n",
        "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
        "            kernel_size=3,\n",
        "            dropout=DROPOUT,\n",
        "            num_stations=len(station_cols),\n",
        "            embed_dim=EMBED_DIM).to(DEVICE)\n",
        "\n",
        "# --- Optimizer and Loss ---\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# --- Training loop ---\n",
        "best_loss = float('inf')\n",
        "best_state = None\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # --- Train ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for xb, yb, sid in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(xb, sid), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, sid in val_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            val_loss += criterion(model(xb, sid), yb).item()\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}: Val Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "    # --- Early stopping on val loss ---\n",
        "    if avg_val_loss < best_loss:\n",
        "        best_loss = avg_val_loss\n",
        "        best_state = model.state_dict()\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "# --- Save best model ---\n",
        "model.load_state_dict(best_state)\n",
        "torch.save(model.state_dict(), \"tcn_model_final.pt\")\n",
        "print(\"âœ… Saved model to 'tcn_model_final.pt'\")\n",
        "\n",
        "# --- Predict on test set ---\n",
        "# (keep your current test loop as is â†’ no changes needed there)\n",
        "\n",
        "# --- Predict on bicikelj_test.csv ---\n",
        "test_df = pd.read_csv(\"bicikelj_test.csv\")\n",
        "test_feats = test_df[station_cols].values.astype(np.float32)\n",
        "timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
        "\n",
        "# Time features\n",
        "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
        "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "slo_holidays = holidays.Slovenia()\n",
        "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "\n",
        "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "\n",
        "# Load model for inference\n",
        "model.eval()\n",
        "\n",
        "pred_matrix = np.full_like(test_feats, np.nan)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
        "        if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
        "            for station in station_cols:\n",
        "                s_idx = name_to_idx[station]\n",
        "                nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
        "\n",
        "                seq = []\n",
        "                for t in range(i - HISTORY_LEN, i):\n",
        "                    row = [test_feats[t, s_idx]]\n",
        "                    row += [test_feats[t, j] for j in nn_idx]\n",
        "                    row += list(time_feats[t])\n",
        "                    seq.append(row)\n",
        "                seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "                pred_norm = model(seq, torch.tensor([s_idx], dtype=torch.long, device=DEVICE)).cpu().numpy().flatten()\n",
        "                pred = pred_norm * station_stds[station] + station_means[station]\n",
        "\n",
        "                for j in range(PRED_HORIZON):\n",
        "                    pred_matrix[i + j, s_idx] = pred[j]\n",
        "\n",
        "# Save predictions\n",
        "pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
        "pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
        "rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
        "pred_df_filtered = pred_df[rows_to_output].copy()\n",
        "pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn.csv\", index=False)\n",
        "print(\"âœ… Saved predictions to 'bicikelj_test_predictions_tcn.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4SAOGd4iZO0",
        "outputId": "58e40203-053e-4bf8-d2c3-ce302c39f4fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 144.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 0.3354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Val Loss = 0.3062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 0.3052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Val Loss = 0.2976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.2993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Val Loss = 0.2940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 0.2963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Val Loss = 0.2912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 0.2946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Val Loss = 0.2898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss = 0.2932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Val Loss = 0.2886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss = 0.2923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Val Loss = 0.2891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss = 0.2918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Val Loss = 0.2900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 144.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss = 0.2913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Val Loss = 0.2873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 0.2909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Val Loss = 0.2866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss = 0.2905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Val Loss = 0.2864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss = 0.2904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Val Loss = 0.2866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 145.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss = 0.2902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Val Loss = 0.2866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss = 0.2899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Val Loss = 0.2859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss = 0.2897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Val Loss = 0.2854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss = 0.2897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Val Loss = 0.2858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss = 0.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Val Loss = 0.2855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss = 0.2892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Val Loss = 0.2852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:21<00:00, 147.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss = 0.2891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Val Loss = 0.2852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 144.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss = 0.2890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Val Loss = 0.2851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss = 0.2890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Val Loss = 0.2851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 145.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss = 0.2888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Val Loss = 0.2845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Train Loss = 0.2888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Val Loss = 0.2848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Train Loss = 0.2888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Val Loss = 0.2851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Train Loss = 0.2886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Val Loss = 0.2840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 144.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Train Loss = 0.2886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Val Loss = 0.2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 143.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Train Loss = 0.2886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Val Loss = 0.2857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Train Loss = 0.2885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Val Loss = 0.2848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 144.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Train Loss = 0.2885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Val Loss = 0.2842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:21<00:00, 147.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Loss = 0.2884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Val Loss = 0.2844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Train Loss = 0.2885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Val Loss = 0.2838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Train Loss = 0.2885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Val Loss = 0.2842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:21<00:00, 147.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Train Loss = 0.2883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Val Loss = 0.2858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Train Loss = 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Val Loss = 0.2840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:21<00:00, 147.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Train Loss = 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Val Loss = 0.2841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Train Loss = 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Val Loss = 0.2846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Train Loss = 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Val Loss = 0.2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Train Loss = 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Val Loss = 0.2837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Train Loss = 0.2881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Val Loss = 0.2849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 145.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Train Loss = 0.2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Val Loss = 0.2849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Train Loss = 0.2879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Val Loss = 0.2842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:21<00:00, 147.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Train Loss = 0.2881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Val Loss = 0.2844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:21<00:00, 147.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Train Loss = 0.2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Val Loss = 0.2845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 145.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Train Loss = 0.2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Val Loss = 0.2848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:22<00:00, 146.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Train Loss = 0.2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Val Loss = 0.2842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:23<00:00, 144.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Train Loss = 0.2879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Val Loss = 0.2850\n",
            "Early stopping!\n",
            "âœ… Saved model to 'tcn_model_final.pt'\n",
            "âœ… Saved predictions to 'bicikelj_test_predictions_tcn.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predict only the unknown rows in bicikelj_test.csv using final TCN model ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "import holidays\n",
        "\n",
        "# --- Constants ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EMBED_DIM = 8\n",
        "HIDDEN_DIM = 64\n",
        "N_LAYERS = 3\n",
        "DROPOUT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# --- Load metadata ---\n",
        "meta = pd.read_csv(\"bicikelj_metadata.csv\")\n",
        "station_cols = pd.read_csv(\"bicikelj_test.csv\").columns[1:]\n",
        "station_names = meta['name'].tolist()\n",
        "\n",
        "# --- Neighbors ---\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- Load training stats for normalization ---\n",
        "df_train = pd.read_csv(\"bicikelj_train.csv\")\n",
        "station_means = df_train[station_cols].mean()\n",
        "station_stds = df_train[station_cols].std().replace(0, 1)\n",
        "\n",
        "# --- TCN Model definition ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]\n",
        "        emb = self.embedding(station_id)\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# --- Load model ---\n",
        "model = TCN(input_size=1 + K_NEIGHBORS + 8,\n",
        "            output_size=PRED_HORIZON,\n",
        "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
        "            kernel_size=3,\n",
        "            dropout=DROPOUT,\n",
        "            num_stations=len(station_cols),\n",
        "            embed_dim=EMBED_DIM).to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(\"tcn_model_final.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# --- Load test set ---\n",
        "test_df = pd.read_csv(\"bicikelj_test.csv\")\n",
        "test_feats = test_df[station_cols].values.astype(np.float32)\n",
        "timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
        "\n",
        "# --- Time features ---\n",
        "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
        "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "slo_holidays = holidays.Slovenia()\n",
        "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "\n",
        "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "# --- Normalize test_feats using training stats ---\n",
        "test_feats_norm = (test_feats - station_means.values) / station_stds.values\n",
        "\n",
        "# --- Predict ---\n",
        "name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "\n",
        "pred_matrix = np.full_like(test_feats, np.nan)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
        "        if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
        "            for station in station_cols:\n",
        "                s_idx = name_to_idx[station]\n",
        "                nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
        "\n",
        "                seq = []\n",
        "                for t in range(i - HISTORY_LEN, i):\n",
        "                    row = [test_feats_norm[t, s_idx]]\n",
        "                    row += [test_feats_norm[t, j] for j in nn_idx]\n",
        "                    row += list(time_feats[t])\n",
        "                    seq.append(row)\n",
        "\n",
        "                seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
        "                sid_tensor = torch.tensor([s_idx], dtype=torch.long, device=DEVICE)\n",
        "\n",
        "                pred_norm = model(seq, sid_tensor).cpu().numpy().flatten()\n",
        "                pred = pred_norm * station_stds[station] + station_means[station]\n",
        "\n",
        "                for j in range(PRED_HORIZON):\n",
        "                    pred_matrix[i + j, s_idx] = pred[j]\n",
        "\n",
        "# --- Save predictions ---\n",
        "pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
        "pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
        "\n",
        "rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
        "pred_df_filtered = pred_df[rows_to_output].copy()\n",
        "\n",
        "pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn.csv\", index=False)\n",
        "print(\"âœ… Saved predictions to 'bicikelj_test_predictions_tcn.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz2PT_0T1Nor",
        "outputId": "5687b2ae-4936-4a07-dd38-8e6a61de1c18"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved predictions to 'bicikelj_test_predictions_tcn.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiheaded output"
      ],
      "metadata": {
        "id": "hLYjcJez30x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "import random\n",
        "\n",
        "# --- Static Params ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "EPOCHS = 20\n",
        "PATIENCE = 5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_COMBINATIONS = 20\n",
        "TRAIN_FRACTION = 0.01\n",
        "EMBED_DIM = 8\n",
        "\n",
        "# --- Load data ---\n",
        "df = pd.read_csv('bicikelj_train.csv')\n",
        "meta = pd.read_csv('bicikelj_metadata.csv')\n",
        "station_cols = df.columns[1:]\n",
        "\n",
        "# Clean and fill\n",
        "for col in station_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df[station_cols] = df[station_cols].ffill().bfill()\n",
        "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
        "\n",
        "# --- Station normalization ---\n",
        "station_means = df[station_cols].mean()\n",
        "station_stds = df[station_cols].std().replace(0, 1)\n",
        "df_norm = df.copy()\n",
        "df_norm[station_cols] = (df[station_cols] - station_means) / station_stds\n",
        "\n",
        "# --- Neighbors ---\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "station_names = meta['name'].tolist()\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- Dataset ---\n",
        "class SharedTCNDataset(Dataset):\n",
        "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon):\n",
        "        self.samples = []\n",
        "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "        timestamps = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
        "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "        slo_holidays = holidays.Slovenia()\n",
        "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "        time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                               month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "        bikes = df[station_cols].values.astype(np.float32)\n",
        "        N = len(df)\n",
        "\n",
        "        for s_name in station_cols:\n",
        "            s_idx = self.station_to_idx[s_name]\n",
        "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
        "            series = bikes[:, [s_idx] + nn_idx]\n",
        "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
        "\n",
        "            for i in range(history_len, N - pred_horizon + 1):\n",
        "                x = full_feats[i - history_len:i]\n",
        "                y = bikes[i:i + pred_horizon, s_idx]\n",
        "                self.samples.append((x, y, s_idx))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, sid = self.samples[idx]\n",
        "        return (torch.tensor(x, dtype=torch.float32),\n",
        "                torch.tensor(y, dtype=torch.float32),\n",
        "                torch.tensor(sid, dtype=torch.long))\n",
        "\n",
        "# --- TCN block ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]  # crop end\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "\n",
        "        # Multihead\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 1)\n",
        "            ) for _ in range(output_size)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]\n",
        "        emb = self.embedding(station_id)\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "\n",
        "        out = [head(combined) for head in self.heads]  # list of [B,1]\n",
        "        out = torch.cat(out, dim=1)  # [B, PRED_HORIZON]\n",
        "        return out\n",
        "\n",
        "\n",
        "# --- Training ---\n",
        "def train_tcn(model, train_loader, val_loader, lr, weight_decay):\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.MSELoss()\n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for xb, yb, sid in train_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb, sid), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, sid in val_loader:\n",
        "                xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "                val_loss += criterion(model(xb, sid), yb).item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model, best_loss\n",
        "\n",
        "# --- Grid search ---\n",
        "param_grid = {\n",
        "    'hidden_dim': [32, 64, 128],\n",
        "    'dropout': [0.0, 0.1, 0.2],\n",
        "    'lr': [1e-3, 5e-4, 2e-4],\n",
        "    'weight_decay': [0.0, 1e-5, 1e-4]\n",
        "    # 'hidden_dim': [64],\n",
        "    # 'dropout': [0.2],\n",
        "    # 'lr': [0.0005],\n",
        "    # 'weight_decay': [0.0001]\n",
        "}\n",
        "param_combos = list(itertools.product(*param_grid.values()))\n",
        "random.shuffle(param_combos)\n",
        "param_combos = param_combos[:MAX_COMBINATIONS]\n",
        "\n",
        "# --- Dataset ---\n",
        "dataset = SharedTCNDataset(df_norm, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON)\n",
        "N = len(dataset)\n",
        "reduced_N = int(N * TRAIN_FRACTION)\n",
        "indices = list(range(N))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_size = int(reduced_N * 0.7)\n",
        "val_size = int(reduced_N * 0.15)\n",
        "holdout_size = reduced_N - train_size - val_size\n",
        "\n",
        "train_set = Subset(dataset, indices[:train_size])\n",
        "val_set = Subset(dataset, indices[train_size:train_size + val_size])\n",
        "holdout_set = Subset(dataset, indices[train_size + val_size:train_size + val_size + holdout_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64)\n",
        "holdout_loader = DataLoader(holdout_set, batch_size=64)\n",
        "\n",
        "# --- Run ---\n",
        "input_dim = 1 + K_NEIGHBORS + 8  # station + neighbors + time features\n",
        "output_dim = PRED_HORIZON\n",
        "num_stations = len(station_cols)\n",
        "\n",
        "n_layers = 4\n",
        "\n",
        "results = []\n",
        "print(f\"â³ Running grid search over {len(param_combos)} combinations...\")\n",
        "for i, (hdim, dr, lr, wd) in enumerate(param_combos):\n",
        "    print(f\"\\nðŸ” Combo {i+1}: hidden_dim={hdim}, dropout={dr}, lr={lr}, weight_decay={wd}\")\n",
        "    model = TCN(input_size=input_dim,\n",
        "                output_size=output_dim,\n",
        "                #num_channels=[hdim] * 3,\n",
        "                num_channels=[hdim] * n_layers,\n",
        "\n",
        "                kernel_size=3,\n",
        "                dropout=dr,\n",
        "                num_stations=num_stations,\n",
        "                embed_dim=EMBED_DIM)\n",
        "    model, val_loss = train_tcn(model, train_loader, val_loader, lr, wd)\n",
        "\n",
        "    model.eval()\n",
        "    holdout_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, sid in holdout_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            holdout_loss += criterion(model(xb, sid), yb).item()\n",
        "    holdout_loss /= len(holdout_loader)\n",
        "\n",
        "    print(f\"âœ… Val Loss: {val_loss:.4f}, Holdout Loss: {holdout_loss:.4f}\")\n",
        "    results.append({\n",
        "        \"hidden_dim\": hdim,\n",
        "        \"dropout\": dr,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": wd,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"holdout_loss\": holdout_loss\n",
        "    })\n",
        "\n",
        "# --- Save ---\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"holdout_loss\")\n",
        "results_df.to_csv(\"grid_search_tcn_results.csv\", index=False)\n",
        "print(\"\\nðŸ“Š Top 5 Results:\")\n",
        "print(results_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "NF8BG34D32LQ",
        "outputId": "bc7d44e0-0fa5-4647-87f1-5ab222e869ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Running grid search over 20 combinations...\n",
            "\n",
            "ðŸ” Combo 1: hidden_dim=32, dropout=0.0, lr=0.0005, weight_decay=0.0001\n",
            "âœ… Val Loss: 0.3813, Holdout Loss: 0.4025\n",
            "\n",
            "ðŸ” Combo 2: hidden_dim=64, dropout=0.1, lr=0.0002, weight_decay=0.0001\n",
            "âœ… Val Loss: 0.3615, Holdout Loss: 0.3727\n",
            "\n",
            "ðŸ” Combo 3: hidden_dim=128, dropout=0.0, lr=0.0002, weight_decay=1e-05\n",
            "âœ… Val Loss: 0.3846, Holdout Loss: 0.4234\n",
            "\n",
            "ðŸ” Combo 4: hidden_dim=64, dropout=0.1, lr=0.001, weight_decay=1e-05\n",
            "âœ… Val Loss: 0.3610, Holdout Loss: 0.3699\n",
            "\n",
            "ðŸ” Combo 5: hidden_dim=64, dropout=0.2, lr=0.0005, weight_decay=1e-05\n",
            "âœ… Val Loss: 0.3588, Holdout Loss: 0.3673\n",
            "\n",
            "ðŸ” Combo 6: hidden_dim=32, dropout=0.1, lr=0.001, weight_decay=0.0\n",
            "âœ… Val Loss: 0.3616, Holdout Loss: 0.3744\n",
            "\n",
            "ðŸ” Combo 7: hidden_dim=128, dropout=0.2, lr=0.0005, weight_decay=0.0001\n",
            "âœ… Val Loss: 0.3616, Holdout Loss: 0.3730\n",
            "\n",
            "ðŸ” Combo 8: hidden_dim=32, dropout=0.0, lr=0.001, weight_decay=0.0001\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e3d16eeff858>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mnum_stations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_stations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 embed_dim=EMBED_DIM)\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e3d16eeff858>\u001b[0m in \u001b[0;36mtrain_tcn\u001b[0;34m(model, train_loader, val_loader, lr, weight_decay)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weather"
      ],
      "metadata": {
        "id": "rg3zFGV95Lw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "import random\n",
        "\n",
        "# --- Static Params ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "EPOCHS = 20\n",
        "PATIENCE = 5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_COMBINATIONS = 20\n",
        "TRAIN_FRACTION = 0.01\n",
        "EMBED_DIM = 8\n",
        "\n",
        "# --- Load data ---\n",
        "df = pd.read_csv('bicikelj_train.csv')\n",
        "meta = pd.read_csv('bicikelj_metadata.csv')\n",
        "station_cols = df.columns[1:]\n",
        "\n",
        "# Clean and fill\n",
        "for col in station_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "df[station_cols] = df[station_cols].ffill().bfill()\n",
        "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
        "\n",
        "# --- Load weather ---\n",
        "# Load weather\n",
        "weather_df = pd.read_csv(\"weather_ljubljana.csv\", skiprows=2)\n",
        "weather_df = weather_df.rename(columns={\n",
        "    'temperature_2m (Â°C)': 'temperature_2m',\n",
        "    'precipitation (mm)': 'precipitation',\n",
        "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
        "    'cloudcover (%)': 'cloudcover'\n",
        "})\n",
        "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
        "\n",
        "# Align timestamp formats\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)\n",
        "\n",
        "# Merge\n",
        "df_merged = pd.merge(df, weather_df, left_on='timestamp', right_on='time', how='left')\n",
        "\n",
        "\n",
        "# Weather features to use\n",
        "weather_features = ['temperature_2m', 'precipitation', 'windspeed_10m', 'cloudcover']\n",
        "df_merged[weather_features] = df_merged[weather_features].ffill().bfill()\n",
        "\n",
        "# Normalize station + weather\n",
        "station_means = df_merged[station_cols].mean()\n",
        "station_stds = df_merged[station_cols].std().replace(0, 1)\n",
        "df_norm = df_merged.copy()\n",
        "df_norm[station_cols] = (df_merged[station_cols] - station_means) / station_stds\n",
        "\n",
        "weather_means = df_merged[weather_features].mean()\n",
        "weather_stds = df_merged[weather_features].std().replace(0, 1)\n",
        "df_norm[weather_features] = (df_merged[weather_features] - weather_means) / weather_stds\n",
        "\n",
        "# --- Neighbors ---\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "station_names = meta['name'].tolist()\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- Dataset ---\n",
        "class SharedTCNDataset(Dataset):\n",
        "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon, weather_features):\n",
        "        self.samples = []\n",
        "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "        timestamps = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
        "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "        slo_holidays = holidays.Slovenia()\n",
        "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "\n",
        "        weather_array = df[weather_features].values  # [N, W]\n",
        "\n",
        "        time_feats = np.concatenate([\n",
        "            np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                      month_sin, month_cos, is_weekend, is_holiday], axis=1),\n",
        "            weather_array\n",
        "        ], axis=1)  # [N, 8+W]\n",
        "\n",
        "        bikes = df[station_cols].values.astype(np.float32)\n",
        "        N = len(df)\n",
        "\n",
        "        for s_name in station_cols:\n",
        "            s_idx = self.station_to_idx[s_name]\n",
        "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
        "            series = bikes[:, [s_idx] + nn_idx]\n",
        "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
        "\n",
        "            for i in range(history_len, N - pred_horizon + 1):\n",
        "                x = full_feats[i - history_len:i]\n",
        "                y = bikes[i:i + pred_horizon, s_idx]\n",
        "                self.samples.append((x, y, s_idx))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, sid = self.samples[idx]\n",
        "        return (torch.tensor(x, dtype=torch.float32),\n",
        "                torch.tensor(y, dtype=torch.float32),\n",
        "                torch.tensor(sid, dtype=torch.long))\n",
        "\n",
        "# --- TCN block ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "\n",
        "        # Multihead:\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 1)\n",
        "            ) for _ in range(output_size)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]\n",
        "        emb = self.embedding(station_id)\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "        out = [head(combined) for head in self.heads]\n",
        "        out = torch.cat(out, dim=1)\n",
        "        return out\n",
        "\n",
        "# --- Training ---\n",
        "def train_tcn(model, train_loader, val_loader, lr, weight_decay):\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.MSELoss()\n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for xb, yb, sid in train_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb, sid), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, sid in val_loader:\n",
        "                xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "                val_loss += criterion(model(xb, sid), yb).item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model, best_loss\n",
        "\n",
        "# --- Grid search ---\n",
        "param_grid = {\n",
        "    'hidden_dim': [64],\n",
        "    'dropout': [0.2],\n",
        "    'lr': [0.0005],\n",
        "    'weight_decay': [0.0001]\n",
        "}\n",
        "param_combos = list(itertools.product(*param_grid.values()))\n",
        "random.shuffle(param_combos)\n",
        "param_combos = param_combos[:MAX_COMBINATIONS]\n",
        "\n",
        "# --- Dataset ---\n",
        "dataset = SharedTCNDataset(df_norm, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON, weather_features)\n",
        "N = len(dataset)\n",
        "reduced_N = int(N * TRAIN_FRACTION)\n",
        "indices = list(range(N))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_size = int(reduced_N * 0.7)\n",
        "val_size = int(reduced_N * 0.15)\n",
        "holdout_size = reduced_N - train_size - val_size\n",
        "\n",
        "train_set = Subset(dataset, indices[:train_size])\n",
        "val_set = Subset(dataset, indices[train_size:train_size + val_size])\n",
        "holdout_set = Subset(dataset, indices[train_size + val_size:train_size + val_size + holdout_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64)\n",
        "holdout_loader = DataLoader(holdout_set, batch_size=64)\n",
        "\n",
        "# --- Run ---\n",
        "input_dim = 1 + K_NEIGHBORS + (8 + len(weather_features))\n",
        "output_dim = PRED_HORIZON\n",
        "num_stations = len(station_cols)\n",
        "n_layers = 4\n",
        "\n",
        "results = []\n",
        "print(f\"â³ Running grid search over {len(param_combos)} combinations...\")\n",
        "for i, (hdim, dr, lr, wd) in enumerate(param_combos):\n",
        "    print(f\"\\nðŸ” Combo {i+1}: hidden_dim={hdim}, dropout={dr}, lr={lr}, weight_decay={wd}\")\n",
        "    model = TCN(input_size=input_dim,\n",
        "                output_size=output_dim,\n",
        "                num_channels=[hdim] * n_layers,\n",
        "                kernel_size=3,\n",
        "                dropout=dr,\n",
        "                num_stations=num_stations,\n",
        "                embed_dim=EMBED_DIM)\n",
        "    model, val_loss = train_tcn(model, train_loader, val_loader, lr, wd)\n",
        "\n",
        "    model.eval()\n",
        "    holdout_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, sid in holdout_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            holdout_loss += criterion(model(xb, sid), yb).item()\n",
        "    holdout_loss /= len(holdout_loader)\n",
        "\n",
        "    print(f\"âœ… Val Loss: {val_loss:.4f}, Holdout Loss: {holdout_loss:.4f}\")\n",
        "    results.append({\n",
        "        \"hidden_dim\": hdim,\n",
        "        \"dropout\": dr,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": wd,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"holdout_loss\": holdout_loss\n",
        "    })\n",
        "\n",
        "# --- Save ---\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"holdout_loss\")\n",
        "results_df.to_csv(\"grid_search_tcn_results.csv\", index=False)\n",
        "print(\"\\nðŸ“Š Top 5 Results:\")\n",
        "print(results_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwoxrOZq5Mra",
        "outputId": "512a3ab4-a7e2-41bb-dcb8-ac24b36188f2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Running grid search over 1 combinations...\n",
            "\n",
            "ðŸ” Combo 1: hidden_dim=64, dropout=0.2, lr=0.0005, weight_decay=0.0001\n",
            "âœ… Val Loss: 0.3718, Holdout Loss: 0.3555\n",
            "\n",
            "ðŸ“Š Top 5 Results:\n",
            "   hidden_dim  dropout      lr  weight_decay  val_loss  holdout_loss\n",
            "0          64      0.2  0.0005        0.0001  0.371804      0.355488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined weather"
      ],
      "metadata": {
        "id": "QVz9hK7M9Kfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TCN Bicikelj final training + test prediction with weather ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from tqdm import tqdm\n",
        "import holidays\n",
        "import random\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EMBED_DIM = 8\n",
        "HIDDEN_DIM = 64\n",
        "N_LAYERS = 4\n",
        "LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0001\n",
        "DROPOUT = 0.2\n",
        "EPOCHS = 50\n",
        "PATIENCE = 8\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# --- Load data ---\n",
        "df = pd.read_csv(\"bicikelj_train.csv\")\n",
        "meta = pd.read_csv(\"bicikelj_metadata.csv\")\n",
        "station_cols = df.columns[1:]\n",
        "\n",
        "# Clean and fill\n",
        "for col in station_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "df[station_cols] = df[station_cols].ffill().bfill()\n",
        "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
        "\n",
        "# --- Load weather ---\n",
        "weather_df = pd.read_csv(\"weather_ljubljana.csv\", skiprows=2)\n",
        "weather_df = weather_df.rename(columns={\n",
        "    'temperature_2m (Â°C)': 'temperature_2m',\n",
        "    'precipitation (mm)': 'precipitation',\n",
        "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
        "    'cloudcover (%)': 'cloudcover'\n",
        "})\n",
        "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)\n",
        "df_merged = pd.merge(df, weather_df, left_on='timestamp', right_on='time', how='left')\n",
        "\n",
        "weather_features = ['temperature_2m', 'precipitation', 'windspeed_10m', 'cloudcover']\n",
        "df_merged[weather_features] = df_merged[weather_features].ffill().bfill()\n",
        "\n",
        "# --- Normalize ---\n",
        "station_means = df_merged[station_cols].mean()\n",
        "station_stds = df_merged[station_cols].std().replace(0, 1)\n",
        "df_norm = df_merged.copy()\n",
        "df_norm[station_cols] = (df_merged[station_cols] - station_means) / station_stds\n",
        "\n",
        "weather_means = df_merged[weather_features].mean()\n",
        "weather_stds = df_merged[weather_features].std().replace(0, 1)\n",
        "df_norm[weather_features] = (df_merged[weather_features] - weather_means) / weather_stds\n",
        "\n",
        "# --- Neighbors ---\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "station_names = meta['name'].tolist()\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- Dataset ---\n",
        "class SharedTCNDataset(Dataset):\n",
        "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon, weather_features):\n",
        "        self.samples = []\n",
        "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "        timestamps = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "        slo_holidays = holidays.Slovenia()\n",
        "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "\n",
        "        weather_array = df[weather_features].values\n",
        "\n",
        "        time_feats = np.concatenate([\n",
        "            np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                      month_sin, month_cos, is_weekend, is_holiday], axis=1),\n",
        "            weather_array\n",
        "        ], axis=1)\n",
        "\n",
        "        bikes = df[station_cols].values.astype(np.float32)\n",
        "        N = len(df)\n",
        "\n",
        "        for s_name in station_cols:\n",
        "            s_idx = self.station_to_idx[s_name]\n",
        "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
        "            series = bikes[:, [s_idx] + nn_idx]\n",
        "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
        "\n",
        "            for i in range(history_len, N - pred_horizon + 1):\n",
        "                x = full_feats[i - history_len:i]\n",
        "                y = bikes[i:i + pred_horizon, s_idx]\n",
        "                self.samples.append((x, y, s_idx))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, sid = self.samples[idx]\n",
        "        return (torch.tensor(x, dtype=torch.float32),\n",
        "                torch.tensor(y, dtype=torch.float32),\n",
        "                torch.tensor(sid, dtype=torch.long))\n",
        "\n",
        "# --- TCN Block ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]\n",
        "        emb = self.embedding(station_id)\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# --- Training ---\n",
        "dataset = SharedTCNDataset(df_norm, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON, weather_features)\n",
        "N = len(dataset)\n",
        "indices = list(range(N))\n",
        "random.shuffle(indices)\n",
        "\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_indices = indices[:train_size]\n",
        "val_indices = indices[train_size:]\n",
        "\n",
        "train_set = Subset(dataset, train_indices)\n",
        "val_set = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
        "\n",
        "model = TCN(input_size=1 + K_NEIGHBORS + (8 + len(weather_features)),\n",
        "            output_size=PRED_HORIZON,\n",
        "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
        "            kernel_size=3,\n",
        "            dropout=DROPOUT,\n",
        "            num_stations=len(station_cols),\n",
        "            embed_dim=EMBED_DIM).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_state = None\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for xb, yb, sid in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(xb, sid), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, sid in val_loader:\n",
        "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
        "            val_loss += criterion(model(xb, sid), yb).item()\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}: Val Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "    if avg_val_loss < best_loss:\n",
        "        best_loss = avg_val_loss\n",
        "        best_state = model.state_dict()\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_state)\n",
        "torch.save(model.state_dict(), \"tcn_model_final_weather.pt\")\n",
        "print(\"âœ… Saved model to 'tcn_model_final_weather.pt'\")\n",
        "\n",
        "# PREDICTION\n",
        "# --- Load model ---\n",
        "model = TCN(input_size=1 + K_NEIGHBORS + (8 + len(weather_features)),\n",
        "            output_size=PRED_HORIZON,\n",
        "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
        "            kernel_size=3,\n",
        "            dropout=DROPOUT,\n",
        "            num_stations=len(station_cols),\n",
        "            embed_dim=EMBED_DIM).to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(\"tcn_model_final_weather.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# --- Load test set ---\n",
        "test_df = pd.read_csv(\"bicikelj_test.csv\")\n",
        "test_feats = test_df[station_cols].values.astype(np.float32)\n",
        "timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
        "\n",
        "# --- Load weather for test ---\n",
        "weather_test_df = pd.read_csv(\"weather_ljubljana_test.csv\", skiprows=2)\n",
        "weather_test_df = weather_test_df.rename(columns={\n",
        "    'temperature_2m (Â°C)': 'temperature_2m',\n",
        "    'precipitation (mm)': 'precipitation',\n",
        "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
        "    'cloudcover (%)': 'cloudcover'\n",
        "})\n",
        "weather_test_df['time'] = pd.to_datetime(weather_test_df['time'])\n",
        "test_df['timestamp'] = pd.to_datetime(test_df['timestamp']).dt.tz_localize(None)\n",
        "test_df_merged = pd.merge(test_df, weather_test_df, left_on='timestamp', right_on='time', how='left')\n",
        "test_df_merged[weather_features] = test_df_merged[weather_features].ffill().bfill()\n",
        "\n",
        "# --- Time features ---\n",
        "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "slo_holidays = holidays.Slovenia()\n",
        "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "\n",
        "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "# --- Normalize test_feats and weather ---\n",
        "test_feats_norm = (test_feats - station_means.values) / station_stds.values\n",
        "weather_feats_norm = (test_df_merged[weather_features].values - weather_means.values) / weather_stds.values\n",
        "\n",
        "# --- Predict ---\n",
        "name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "pred_matrix = np.full_like(test_feats, np.nan)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
        "        if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
        "            for station in station_cols:\n",
        "                s_idx = name_to_idx[station]\n",
        "                nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
        "\n",
        "                seq = []\n",
        "                for t in range(i - HISTORY_LEN, i):\n",
        "                    row = [test_feats_norm[t, s_idx]]\n",
        "                    row += [test_feats_norm[t, j] for j in nn_idx]\n",
        "                    row += list(time_feats[t])\n",
        "                    row += list(weather_feats_norm[t])\n",
        "                    seq.append(row)\n",
        "\n",
        "                seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
        "                sid_tensor = torch.tensor([s_idx], dtype=torch.long, device=DEVICE)\n",
        "\n",
        "                pred_norm = model(seq, sid_tensor).cpu().numpy().flatten()\n",
        "                pred = pred_norm * station_stds[station] + station_means[station]\n",
        "\n",
        "                for j in range(PRED_HORIZON):\n",
        "                    pred_matrix[i + j, s_idx] = pred[j]\n",
        "\n",
        "# --- Save predictions ---\n",
        "pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
        "pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
        "\n",
        "rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
        "pred_df_filtered = pred_df[rows_to_output].copy()\n",
        "\n",
        "pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn_weather.csv\", index=False)\n",
        "print(\"âœ… Saved predictions to 'bicikelj_test_predictions_tcn_weather.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKZP3b2b96fa",
        "outputId": "79b2e108-4db1-4d3e-c256-af855502d33d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 0.3238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Val Loss = 0.2979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 0.2985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Val Loss = 0.2907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.2932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Val Loss = 0.2876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 0.2905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Val Loss = 0.2859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 125.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 0.2889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Val Loss = 0.2852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 129.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss = 0.2878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Val Loss = 0.2840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss = 0.2868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Val Loss = 0.2822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss = 0.2861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Val Loss = 0.2821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss = 0.2856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Val Loss = 0.2815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 0.2851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Val Loss = 0.2811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss = 0.2846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Val Loss = 0.2803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss = 0.2843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Val Loss = 0.2799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss = 0.2837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Val Loss = 0.2799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss = 0.2834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Val Loss = 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 128.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss = 0.2831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Val Loss = 0.2794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss = 0.2830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Val Loss = 0.2788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss = 0.2826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Val Loss = 0.2795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss = 0.2824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Val Loss = 0.2785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:32<00:00, 129.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss = 0.2824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Val Loss = 0.2777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss = 0.2822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Val Loss = 0.2804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss = 0.2822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Val Loss = 0.2776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss = 0.2819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Val Loss = 0.2773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:36<00:00, 125.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Train Loss = 0.2817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Val Loss = 0.2770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Train Loss = 0.2817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Val Loss = 0.2779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Train Loss = 0.2817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Val Loss = 0.2771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Train Loss = 0.2815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Val Loss = 0.2779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:36<00:00, 125.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Train Loss = 0.2815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Val Loss = 0.2788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Train Loss = 0.2814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Val Loss = 0.2775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Train Loss = 0.2813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Val Loss = 0.2773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Loss = 0.2813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Val Loss = 0.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Train Loss = 0.2812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Val Loss = 0.2787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 128.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Train Loss = 0.2811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Val Loss = 0.2773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Train Loss = 0.2811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Val Loss = 0.2781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 125.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Train Loss = 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Val Loss = 0.2775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 128.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Train Loss = 0.2810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Val Loss = 0.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Train Loss = 0.2810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Val Loss = 0.2766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Train Loss = 0.2810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Val Loss = 0.2767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 128.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Train Loss = 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Val Loss = 0.2767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Train Loss = 0.2811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Val Loss = 0.2770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Train Loss = 0.2809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Val Loss = 0.2763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:33<00:00, 128.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Train Loss = 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Val Loss = 0.2767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Train Loss = 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Val Loss = 0.2759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Train Loss = 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Val Loss = 0.2766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:36<00:00, 125.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Train Loss = 0.2806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Val Loss = 0.2763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Train Loss = 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Val Loss = 0.2756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Train Loss = 0.2806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Val Loss = 0.2757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: Train Loss = 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: Val Loss = 0.2770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: Train Loss = 0.2805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: Val Loss = 0.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:34<00:00, 127.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: Train Loss = 0.2805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: Val Loss = 0.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12056/12056 [01:35<00:00, 126.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: Train Loss = 0.2806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: Val Loss = 0.2769\n",
            "âœ… Saved model to 'tcn_model_final_weather.pt'\n",
            "âœ… Saved predictions to 'bicikelj_test_predictions_tcn_weather.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP"
      ],
      "metadata": {
        "id": "ybmc60rOAb0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP analysis for trained TCN model ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import holidays\n",
        "import shap\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "\n",
        "# --- Constants ---\n",
        "HISTORY_LEN = 48\n",
        "PRED_HORIZON = 4\n",
        "K_NEIGHBORS = 2\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMBED_DIM = 8\n",
        "HIDDEN_DIM = 64\n",
        "N_LAYERS = 3\n",
        "DROPOUT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "weather_features = ['temperature_2m', 'precipitation', 'windspeed_10m', 'cloudcover']\n",
        "\n",
        "# --- Load training data and weather ---\n",
        "df_train = pd.read_csv(\"bicikelj_train.csv\")\n",
        "meta = pd.read_csv(\"bicikelj_metadata.csv\")\n",
        "station_cols = df_train.columns[1:]\n",
        "\n",
        "weather_df = pd.read_csv(\"weather_ljubljana.csv\", skiprows=2)\n",
        "weather_df = weather_df.rename(columns={\n",
        "    'temperature_2m (Â°C)': 'temperature_2m',\n",
        "    'precipitation (mm)': 'precipitation',\n",
        "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
        "    'cloudcover (%)': 'cloudcover'\n",
        "})\n",
        "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
        "df_train['timestamp'] = pd.to_datetime(df_train['timestamp']).dt.tz_localize(None)\n",
        "df_train_merged = pd.merge(df_train, weather_df, left_on='timestamp', right_on='time', how='left')\n",
        "df_train_merged[weather_features] = df_train_merged[weather_features].ffill().bfill()\n",
        "\n",
        "# --- Station normalization ---\n",
        "station_means = df_train_merged[station_cols].mean()\n",
        "station_stds = df_train_merged[station_cols].std().replace(0, 1)\n",
        "df_norm = df_train_merged.copy()\n",
        "df_norm[station_cols] = (df_train_merged[station_cols] - station_means) / station_stds\n",
        "\n",
        "# --- Weather normalization ---\n",
        "weather_means = df_train_merged[weather_features].mean()\n",
        "weather_stds = df_train_merged[weather_features].std().replace(0, 1)\n",
        "df_norm[weather_features] = (df_train_merged[weather_features] - weather_means) / weather_stds\n",
        "\n",
        "# --- Neighbors ---\n",
        "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
        "station_names = meta['name'].tolist()\n",
        "dists = haversine_distances(coords, coords) * 6371\n",
        "neighbors = {}\n",
        "for i, name in enumerate(station_names):\n",
        "    order = np.argsort(dists[i])\n",
        "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
        "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
        "\n",
        "# --- TCN model definition ---\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=self.padding, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = out[:, :, :-self.padding]\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return out + res\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        tcn_out = self.tcn(x)[:, :, -1]\n",
        "        emb = self.embedding(station_id)\n",
        "        combined = torch.cat([tcn_out, emb], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# --- Load model ---\n",
        "model = TCN(input_size=1 + K_NEIGHBORS + (8 + len(weather_features)),\n",
        "            output_size=PRED_HORIZON,\n",
        "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
        "            kernel_size=3,\n",
        "            dropout=DROPOUT,\n",
        "            num_stations=len(station_cols),\n",
        "            embed_dim=EMBED_DIM).to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(\"tcn_model_final_weather.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# --- Prepare sample batch for SHAP ---\n",
        "# We'll pick one station for simplicity (you can loop later)\n",
        "s_name = station_cols[0]\n",
        "station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
        "s_idx = station_to_idx[s_name]\n",
        "nn_idx = [station_to_idx[nn] for nn in neighbors[s_name]]\n",
        "\n",
        "timestamps = pd.to_datetime(df_norm['timestamp'])\n",
        "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
        "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
        "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
        "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
        "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
        "slo_holidays = holidays.Slovenia()\n",
        "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
        "\n",
        "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
        "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
        "\n",
        "bikes = df_norm[station_cols].values.astype(np.float32)\n",
        "weather_array = df_norm[weather_features].values.astype(np.float32)\n",
        "\n",
        "X_samples = []\n",
        "Y_samples = []\n",
        "SID_samples = []\n",
        "\n",
        "N = len(df_norm)\n",
        "for i in range(HISTORY_LEN, N - PRED_HORIZON + 1, 50):  # sample 1 every 50 â†’ faster SHAP\n",
        "    series = bikes[:, [s_idx] + nn_idx]\n",
        "    full_feats = np.concatenate([series, time_feats, weather_array], axis=1)\n",
        "\n",
        "    x_seq = full_feats[i - HISTORY_LEN:i]\n",
        "    y_seq = bikes[i:i + PRED_HORIZON, s_idx]\n",
        "\n",
        "    X_samples.append(x_seq)\n",
        "    Y_samples.append(y_seq)\n",
        "    SID_samples.append(s_idx)\n",
        "\n",
        "X_samples = torch.tensor(np.stack(X_samples), dtype=torch.float32).to(DEVICE)\n",
        "SID_samples = torch.tensor(SID_samples, dtype=torch.long).to(DEVICE)\n",
        "\n",
        "# --- SHAP DeepExplainer ---\n",
        "background = X_samples[:50]  # smaller background\n",
        "background_sid = SID_samples[:50]\n",
        "\n",
        "explainer = shap.DeepExplainer(model, [background, background_sid])\n",
        "shap_values = explainer.shap_values([X_samples, SID_samples])\n",
        "\n",
        "# --- Plot SHAP summary for horizon 0 ---\n",
        "shap_array = shap_values[0]  # First horizon\n",
        "\n",
        "# Collapse time axis: (batch, time, features) â†’ (batch, time * features)\n",
        "shap_array_collapsed = shap_array.reshape(shap_array.shape[0], -1)\n",
        "\n",
        "# Feature names:\n",
        "time_feat_names = ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'month_sin', 'month_cos', 'is_weekend', 'is_holiday']\n",
        "feature_names = (\n",
        "    ['station_value'] +\n",
        "    [f'neighbor_{i+1}' for i in range(K_NEIGHBORS)] +\n",
        "    time_feat_names +\n",
        "    weather_features\n",
        ")\n",
        "\n",
        "# For each timestep â†’ repeat feature names\n",
        "full_feature_names = []\n",
        "for t in range(HISTORY_LEN):\n",
        "    for fname in feature_names:\n",
        "        full_feature_names.append(f\"{fname}_t-{HISTORY_LEN - t}\")\n",
        "\n",
        "# --- SHAP summary plot ---\n",
        "shap.summary_plot(shap_array_collapsed, feature_names=full_feature_names, show=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3PatWRbbAc-V",
        "outputId": "e2d7892f-c43d-4820-ea00-dbe83edd8baa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for TCN:\n\tUnexpected key(s) in state_dict: \"tcn.3.conv1.weight\", \"tcn.3.conv1.bias\", \"tcn.3.conv2.weight\", \"tcn.3.conv2.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3d520f31a5b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m             embed_dim=EMBED_DIM).to(DEVICE)\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tcn_model_final_weather.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TCN:\n\tUnexpected key(s) in state_dict: \"tcn.3.conv1.weight\", \"tcn.3.conv1.bias\", \"tcn.3.conv2.weight\", \"tcn.3.conv2.bias\". "
          ]
        }
      ]
    }
  ]
}