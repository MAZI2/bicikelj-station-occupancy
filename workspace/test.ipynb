{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca50515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TCN Bicikelj final training + test prediction with weather ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "import random\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "HISTORY_LEN = 48\n",
    "PRED_HORIZON = 4\n",
    "K_NEIGHBORS = 2\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EMBED_DIM = 8\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYERS = 4\n",
    "LR = 0.0005\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT = 0.2\n",
    "EPOCHS = 50\n",
    "PATIENCE = 8\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_csv(\"../data/bicikelj_train.csv\")\n",
    "meta = pd.read_csv(\"../data/bicikelj_metadata.csv\")\n",
    "station_cols = df.columns[1:]\n",
    "\n",
    "# Clean and fill\n",
    "for col in station_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df[station_cols] = df[station_cols].ffill().bfill()\n",
    "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
    "\n",
    "# --- Load weather ---\n",
    "weather_df = pd.read_csv(\"../data/weather_ljubljana.csv\", skiprows=2)\n",
    "weather_df = weather_df.rename(columns={\n",
    "    'temperature_2m (°C)': 'temperature_2m',\n",
    "    'precipitation (mm)': 'precipitation',\n",
    "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
    "    'cloudcover (%)': 'cloudcover'\n",
    "})\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)\n",
    "df_merged = pd.merge(df, weather_df, left_on='timestamp', right_on='time', how='left')\n",
    "\n",
    "weather_features = ['temperature_2m', 'precipitation', 'windspeed_10m', 'cloudcover']\n",
    "df_merged[weather_features] = df_merged[weather_features].ffill().bfill()\n",
    "\n",
    "# --- Normalize ---\n",
    "station_means = df_merged[station_cols].mean()\n",
    "station_stds = df_merged[station_cols].std().replace(0, 1)\n",
    "df_norm = df_merged.copy()\n",
    "df_norm[station_cols] = (df_merged[station_cols] - station_means) / station_stds\n",
    "\n",
    "weather_means = df_merged[weather_features].mean()\n",
    "weather_stds = df_merged[weather_features].std().replace(0, 1)\n",
    "df_norm[weather_features] = (df_merged[weather_features] - weather_means) / weather_stds\n",
    "\n",
    "# --- Neighbors ---\n",
    "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
    "station_names = meta['name'].tolist()\n",
    "dists = haversine_distances(coords, coords) * 6371\n",
    "neighbors = {}\n",
    "for i, name in enumerate(station_names):\n",
    "    order = np.argsort(dists[i])\n",
    "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
    "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
    "\n",
    "# --- Dataset ---\n",
    "class SharedTCNDataset(Dataset):\n",
    "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon, weather_features):\n",
    "        self.samples = []\n",
    "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "        timestamps = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "        month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "        slo_holidays = holidays.Slovenia()\n",
    "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "\n",
    "        weather_array = df[weather_features].values\n",
    "\n",
    "        time_feats = np.concatenate([\n",
    "            np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
    "                      month_sin, month_cos, is_weekend, is_holiday], axis=1),\n",
    "            weather_array\n",
    "        ], axis=1)\n",
    "\n",
    "        bikes = df[station_cols].values.astype(np.float32)\n",
    "        N = len(df)\n",
    "\n",
    "        for s_name in station_cols:\n",
    "            s_idx = self.station_to_idx[s_name]\n",
    "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
    "            series = bikes[:, [s_idx] + nn_idx]\n",
    "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
    "\n",
    "            for i in range(history_len, N - pred_horizon + 1):\n",
    "                x = full_feats[i - history_len:i]\n",
    "                y = bikes[i:i + pred_horizon, s_idx]\n",
    "                self.samples.append((x, y, s_idx))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, sid = self.samples[idx]\n",
    "        return (torch.tensor(x, dtype=torch.float32),\n",
    "                torch.tensor(y, dtype=torch.float32),\n",
    "                torch.tensor(sid, dtype=torch.long))\n",
    "\n",
    "# --- TCN Block ---\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out[:, :, :-self.padding]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = out[:, :, :-self.padding]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
    "            out_ch = num_channels[i]\n",
    "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, station_id):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        tcn_out = self.tcn(x)[:, :, -1]\n",
    "        emb = self.embedding(station_id)\n",
    "        combined = torch.cat([tcn_out, emb], dim=1)\n",
    "        return self.head(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd533fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to 'bicikelj_test_predictions_tcn_weather.csv'\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION\n",
    "# --- Load model ---\n",
    "model = TCN(input_size=1 + K_NEIGHBORS + (8 + len(weather_features)),\n",
    "            output_size=PRED_HORIZON,\n",
    "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
    "            kernel_size=3,\n",
    "            dropout=DROPOUT,\n",
    "            num_stations=len(station_cols),\n",
    "            embed_dim=EMBED_DIM).to(DEVICE)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"tcn_model_final_weather.pt\"))\n",
    "model.load_state_dict(torch.load(\"tcn_model_final_weather.pt\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# --- Load test set ---\n",
    "test_df = pd.read_csv(\"../data/bicikelj_test.csv\")\n",
    "test_feats = test_df[station_cols].values.astype(np.float32)\n",
    "timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
    "\n",
    "# --- Load weather for test ---\n",
    "weather_test_df = pd.read_csv(\"../data/weather_ljubljana_test.csv\", skiprows=2)\n",
    "weather_test_df = weather_test_df.rename(columns={\n",
    "    'temperature_2m (°C)': 'temperature_2m',\n",
    "    'precipitation (mm)': 'precipitation',\n",
    "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
    "    'cloudcover (%)': 'cloudcover'\n",
    "})\n",
    "weather_test_df['time'] = pd.to_datetime(weather_test_df['time'])\n",
    "test_df['timestamp'] = pd.to_datetime(test_df['timestamp']).dt.tz_localize(None)\n",
    "test_df_merged = pd.merge(test_df, weather_test_df, left_on='timestamp', right_on='time', how='left')\n",
    "test_df_merged[weather_features] = test_df_merged[weather_features].ffill().bfill()\n",
    "\n",
    "# --- Time features ---\n",
    "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "slo_holidays = holidays.Slovenia()\n",
    "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "\n",
    "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
    "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
    "\n",
    "# --- Normalize test_feats and weather ---\n",
    "test_feats_norm = (test_feats - station_means.values) / station_stds.values\n",
    "weather_feats_norm = (test_df_merged[weather_features].values - weather_means.values) / weather_stds.values\n",
    "\n",
    "# --- Predict ---\n",
    "name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "pred_matrix = np.full_like(test_feats, np.nan)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
    "        if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
    "            for station in station_cols:\n",
    "                s_idx = name_to_idx[station]\n",
    "                nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
    "\n",
    "                seq = []\n",
    "                for t in range(i - HISTORY_LEN, i):\n",
    "                    row = [test_feats_norm[t, s_idx]]\n",
    "                    row += [test_feats_norm[t, j] for j in nn_idx]\n",
    "                    row += list(time_feats[t])\n",
    "                    row += list(weather_feats_norm[t])\n",
    "                    seq.append(row)\n",
    "\n",
    "                seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
    "                sid_tensor = torch.tensor([s_idx], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "                pred_norm = model(seq, sid_tensor).cpu().numpy().flatten()\n",
    "                pred = pred_norm * station_stds[station] + station_means[station]\n",
    "\n",
    "                for j in range(PRED_HORIZON):\n",
    "                    pred_matrix[i + j, s_idx] = pred[j]\n",
    "\n",
    "# --- Save predictions ---\n",
    "pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
    "pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
    "\n",
    "rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
    "pred_df_filtered = pred_df[rows_to_output].copy()\n",
    "\n",
    "pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn_weather_verify_2.csv\", index=False)\n",
    "print(\"✅ Saved predictions to 'bicikelj_test_predictions_tcn_weather.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36fbf61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resaved model together with normalization statistics as 'tcn_model_final_with_stats.pt'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Save as checkpoint with normalization stats, as expected by the unified script\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'station_means': station_means,\n",
    "    'station_stds': station_stds,\n",
    "    'weather_means': weather_means,\n",
    "    'weather_stds': weather_stds\n",
    "}, \"tcn_model_final_with_stats.pt\")\n",
    "print(\"✅ Resaved model together with normalization statistics as 'tcn_model_final_with_stats.pt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
