{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75531848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample len:  20463\n",
      "Validation coverage: 2080 (0.102)\n",
      "Train coverage:      18383 (0.898)\n",
      "Number of val sequences: 40\n",
      "Train samples: 8257 | Val samples: 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "import random\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "HISTORY_LEN = 48\n",
    "PRED_HORIZON = 4\n",
    "BATCH_SIZE = 128\n",
    "VAL_FRAC = 0.1\n",
    "STRIDE = 2  # Or whatever stride you want\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_csv(\"../data/bicikelj_train.csv\")\n",
    "meta = pd.read_csv(\"../data/bicikelj_metadata.csv\")\n",
    "station_cols = df.columns[1:]\n",
    "\n",
    "# Clean and fill\n",
    "for col in station_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df[station_cols] = df[station_cols].ffill().bfill()\n",
    "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
    "\n",
    "# --- Load weather ---\n",
    "weather_df = pd.read_csv(\"../data/weather_ljubljana.csv\", skiprows=2)\n",
    "weather_df = weather_df.rename(columns={\n",
    "    'temperature_2m (Â°C)': 'temperature_2m',\n",
    "    'precipitation (mm)': 'precipitation',\n",
    "    'windspeed_10m (km/h)': 'windspeed_10m',\n",
    "    'cloudcover (%)': 'cloudcover'\n",
    "})\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)\n",
    "df_merged = pd.merge(df, weather_df, left_on='timestamp', right_on='time', how='left')\n",
    "weather_features = ['temperature_2m', 'precipitation', 'windspeed_10m', 'cloudcover']\n",
    "df_merged[weather_features] = df_merged[weather_features].ffill().bfill()\n",
    "N = len(df_merged)\n",
    "print(\"sample len: \", N)\n",
    "\n",
    "# --- Randomly select validation cut regions ---\n",
    "BLOCK_SIZE = HISTORY_LEN + PRED_HORIZON\n",
    "np.random.seed(42)\n",
    "all_possible_starts = np.arange(0, N - BLOCK_SIZE + 1)\n",
    "val_mask = np.zeros(N, dtype=bool)\n",
    "val_starts = []\n",
    "target_val_coverage = int(VAL_FRAC * N)\n",
    "covered = 0\n",
    "\n",
    "np.random.shuffle(all_possible_starts)\n",
    "\n",
    "for start in all_possible_starts:\n",
    "    if val_mask[start:start + BLOCK_SIZE].any():\n",
    "        continue  # Skip if this region overlaps with any already taken\n",
    "    val_mask[start:start + BLOCK_SIZE] = True\n",
    "    val_starts.append(start)\n",
    "    covered += BLOCK_SIZE\n",
    "    if covered >= target_val_coverage:\n",
    "        break\n",
    "\n",
    "train_mask = ~val_mask\n",
    "\n",
    "print(f\"Validation coverage: {val_mask.sum()} ({val_mask.sum()/N:.3f})\")\n",
    "print(f\"Train coverage:      {train_mask.sum()} ({train_mask.sum()/N:.3f})\")\n",
    "print(f\"Number of val sequences: {len(val_starts)}\")\n",
    "\n",
    "# --- Strided window sample selection ---\n",
    "def make_sample_indices(mask, history_len, pred_horizon, stride=1):\n",
    "    N = len(mask)\n",
    "    indices = []\n",
    "    for i in range(history_len, N - pred_horizon + 1, stride):\n",
    "        if mask[i - history_len:i + pred_horizon].all():\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "train_indices = make_sample_indices(train_mask, HISTORY_LEN, PRED_HORIZON, stride=STRIDE)\n",
    "val_indices = make_sample_indices(val_mask, HISTORY_LEN, PRED_HORIZON, stride=1)\n",
    "\n",
    "print(f\"Train samples: {len(train_indices)} | Val samples: {len(val_indices)}\")\n",
    "\n",
    "# --- Normalize using only train region statistics ---\n",
    "station_means = df_merged.loc[train_mask, station_cols].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
