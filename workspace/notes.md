# TODO:
HISTORY_LEN = 48
PRED_HORIZON = 4
K_NEIGHBORS = 2
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
EMBED_DIM = 8
HIDDEN_DIM = 64
N_LAYERS = 4
LR = 0.0005
WEIGHT_DECAY = 0.0001
DROPOUT = 0.2
EPOCHS = 50
PATIENCE = 8
BATCH_SIZE = 128

Train:
https://archive-api.open-meteo.com/v1/archive?latitude=46.05&longitude=14.51&start_date=2022-09-01&end_date=2024-12-31&hourly=temperature_2m,precipitation,windspeed_10m,cloudcover&timezone=Europe%2FBerlin&format=csv

Test:
https://archive-api.open-meteo.com/v1/archive?latitude=46.05&longitude=14.51&start_date=2025-01-01&end_date=2025-05-19&hourly=temperature_2m,precipitation,windspeed_10m,cloudcover&timezone=Europe%2FBerlin&format=csv

shap better evaluation
data graphs
How does it test?
stride => step


üìä Top 5 Results:
    hidden_dim  dropout      lr  weight_decay  batch_size  val_loss  \
19          64      0.2  0.0010        0.0001          64  0.309060   
18          64      0.4  0.0005        0.0001         256  0.307775   
13          64      0.4  0.0010        0.0001         128  0.306010   
10          64      0.4  0.0010        0.0000          64  0.307754   
5           64      0.2  0.0010        0.0001          32  0.302331   

    holdout_loss  
19     10.138661  
18     10.177680  
13     10.206712  
10     10.221721  
5      10.228167

Holdout MSE (unnormalized, real units): 9.4291

hidden_dim=64, dropout=0.4, lr=0.001, weight_decay=0.0?
Train samples: 4312 | Val samples: 79
Train samples: 362208 | Val samples: 6636
‚è≥ Running grid search over 1 combinations...

üîç Combo 1: hidden_dim=64, dropout=0.4, lr=0.001, weight_decay=0.0
Holdout MSE (real units): 9.195802937395635

üìä Top 5 Results:
   hidden_dim  dropout     lr  weight_decay  val_loss  holdout_loss
0          64      0.4  0.001           0.0  0.284409      9.195803
vs 256 vs prev on less reduction
Run grid search on a 0.1 reduction and see if it is the same
-----------


I have a task to predict the number of bicycles for 4x 1 hour after a 48 hour sequence. The training data is 2 year worth of such sequences. Each station also has metadata

bicikelj_metadata.csv
name,latitude,longitude
LIDL BE≈ΩIGRAD,46.063797,14.506854
≈†MARTINSKI PARK,46.065206,14.529911
SAVSKO NASELJE 1-≈†MARTINSKA CESTA,46.062475,14.524321
ƒåRNUƒåE,46.102446,14.530213
VILHARJEVA CESTA,46.06005,14.51302
MASARYKOVA DDC,46.05763,14.514264
POGAƒåARJEV TRG-TR≈ΩNICA,46.051093,14.507186
CANKARJEVA UL.-NAMA,46.052431,14.503257
ANTONOV TRG,46.041753,14.477016
PRU≈†NIKOVA,46.090608,14.471637
...

bicikelj_train.csv
timestamp,LIDL BE≈ΩIGRAD,≈†MARTINSKI PARK,SAVSKO NASELJE 1-≈†MARTINSKA CESTA,ƒåRNUƒåE,VILHARJEVA CESTA,MASARYKOVA DDC,POGAƒåARJEV TRG-TR≈ΩNICA,CANKARJEVA UL.-NAMA,ANTONOV TRG,PRU≈†NIKOVA,TEHNOLO≈†KI PARK,KOSE≈†KI BAJER,TIVOLI,TR≈ΩNICA MOSTE,GRUDNOVO NABRE≈ΩJE-KARLOV≈†KA C.,LIDL-LITIJSKA CESTA,≈†PORTNI CENTER STO≈ΩICE,≈†PICA,RO≈†KA - STRELI≈†KA,BAVARSKI DVOR,STARA CERKEV,SITULA,ILIRSKA ULICA,LIDL - RUDNIK,KOPALI≈†ƒåE KOLEZIJA,POV≈†ETOVA - KAJUHOVA,DUNAJSKA C.-PS MERCATOR,CITYPARK,KOPRSKA ULICA,LIDL - VOJKOVA CESTA,POLJANSKA-POTOƒåNIKOVA,POV≈†ETOVA-GRABLOVIƒåEVA,PARK NAVJE-≈ΩELEZNA CESTA,ZALOG,CESTA NA RO≈ΩNIK,HOFER-KAJUHOVA,DUNAJSKA C.-PS PETROL,STUDENEC,PARKIRI≈†ƒåE NUK 2-FF,BRATOV≈†EVA PLO≈†ƒåAD,KONGRESNI TRG-≈†UBIƒåEVA ULICA,BS4-STO≈ΩICE,GERBIƒåEVA - ≈†PORTNI PARK SVOBODA,≈ΩIVALSKI VRT,VOKA - SLOVENƒåEVA,BTC CITY/DVORANA A,TRNOVO,P+R BARJE,RO≈ΩNA DOLINA-≈†KRABƒåEVA UL.,KINO ≈†I≈†KA,BRODARJEV TRG,ZALO≈†KA C.-GRABLOVIƒåEVA C.,DOLENJSKA C. - STRELI≈†ƒåE,≈†TEPANJSKO NASELJE 1-JAKƒåEVA ULICA,SOSESKA NOVO BRDO,TR≈ΩNICA KOSEZE,ALEJA - CELOV≈†KA CESTA,MERCATOR CENTER ≈†I≈†KA,GH ≈†ENTPETER-NJEGO≈†EVA C.,HOFER - POLJE,VI≈†KO POLJE,BONIFACIJA,P + R DOLGI MOST,DRAVLJE,POLJE,SUPERNOVA LJUBLJANA - RUDNIK,SREDNJA FRIZERSKA ≈†OLA,TRG OF-KOLODVORSKA UL.,TRG MDB,TR≈ΩA≈†KA C.-ILIRIJA,PRE≈†ERNOV TRG-PETKOV≈†KOVO NABRE≈ΩJE,MERCATOR MARKET - CELOV≈†KA C. 163,SAVSKO NASELJE 2-LINHARTOVA CESTA,BREG,BTC CITY ATLANTIS,IKEA,MIKLO≈†IƒåEV PARK,BARJANSKA C.-CENTER STAREJ≈†IH TRNOVO,LEK - VEROV≈†KOVA,AMBRO≈ΩEV TRG,VOJKOVA - GASILSKA BRIGADA,RAKOVNIK,PREGLOV TRG,PLEƒåNIKOV STADION
2025-01-01T00:00Z,4.0,20.0,5.0,7.0,17.0,18.0,15.0,13.0,12.0,7.0,4.0,5.0,11.0,13.0,16.0,7.0,9.0,11.0,5.0,19.0,2.0,3.0,8.0,8.0,10.0,13.0,4.0,14.0,4.0,19.0,7.0,7.0,7.0,2.0,7.0,8.0,3.0,11.0,13.0,9.0,19.0,8.0,20.0,4.0,4.0,1.0,13.0,13.0,7.0,8.0,10.0,9.0,3.0,16.0,6.0,12.0,8.0,6.0,7.0,13.0,13.0,15.0,4.0,7.0,14.0,10.0,8.0,21.0,0.0,4.0,20.0,9.0,3.0,19.0,7.0,16.0,13.0,14.0,4.0,18.0,7.0,17.0,6.0,8.0
2025-01-01T01:00Z,5.0,20.0,5.0,7.0,15.0,18.0,15.0,7.0,11.0,7.0,4.0,8.0,5.0,11.0,11.0,6.0,10.0,13.0,5.0,14.0,3.0,2.0,10
...

the test set is the same format as train just that 4 hours are missing after 48 hour sequences. These i need to predict. For this task i can use at most pytorch and its dependencies and scikit learn. I had by far the best result with per station lightgbm, however i cannot use it as it is external library. The second best, but still not that good is lstm, which was better as shared model rather than per station. MLP instead of lstm was not better. I also learned that stations are very weakly correlated regarding spatialy, however if the range is <1km they indeed are quite correlated. What else can i explore? What is the next promising thing to try? The following is the best model with best features



           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ   Bicikelj Data (per station) ‚îÇ
           ‚îÇ    - time series per station  ‚îÇ
           ‚îÇ   Weather Data                ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                         ‚îÇ
    ‚ñº                                         ‚ñº
[Neighbor Selection]                   [Timestamp ‚Üí Features]
  - For each station,                  - hour_sin/cos
    find K nearest                     - dow_sin/cos
    neighbors (by                      - month_sin/cos
    Haversine)                         - is_weekend, is_holiday
                                       - Weather features
    ‚îÇ                                         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ             ‚îÇ
                  ‚ñº             ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ For each sample window:                    ‚îÇ
   ‚îÇ  - Main station time series (HISTORY_LEN)  ‚îÇ
   ‚îÇ  - Neighbor station series (HISTORY_LEN)   ‚îÇ
   ‚îÇ  - Time features + weather (HISTORY_LEN)   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ   X: [history_len, num_features]         ‚îÇ
     ‚îÇ   Station ID                             ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   Shared TCN Block  ‚îÇ
                ‚îÇ (Temporal Conv Net) ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                   Last TCN output
                          ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ Station Embedding     ‚îÇ
                ‚îÇ (lookup by Station ID)‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Concatenate:             ‚îÇ
            ‚îÇ   - TCN output             ‚îÇ
            ‚îÇ   - Station Embedding      ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ  MLP Output Head            ‚îÇ
                 ‚îÇ  - Linear+ReLU              ‚îÇ
                 ‚îÇ  - Linear                   ‚îÇ
                 ‚îÇ  (Dropout in between)       ‚îÇ
                 ‚îÇ  - Final Linear             ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                               ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Output: predicted bikes ‚îÇ
         ‚îÇ    for next PRED_HORIZON  ‚îÇ
         ‚îÇ         time steps        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò



Input: X [B, C_in, L]
(batch size, input channels, sequence length)
   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Conv1d Layer 1 ‚îÇ
  ‚îÇ (C_in ‚Üí C_out) ‚îÇ
  ‚îÇ Kernel size=k, ‚îÇ
  ‚îÇ Padding, Dilation   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
    Remove trailing padding
   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ   ReLU   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  Dropout ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Conv1d Layer 2 ‚îÇ
  ‚îÇ (C_out ‚Üí C_out)‚îÇ
  ‚îÇ Kernel size=k, ‚îÇ
  ‚îÇ Padding, Dilation   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
    Remove trailing padding
   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ   ReLU   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  Dropout ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Residual Connection  ‚îÇ
‚îÇ  (optionally via 1x1    ‚îÇ
‚îÇ   Conv if C_in ‚â† C_out) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
    Add elementwise
   ‚îÇ
 Output: Y [B, C_out, L]

Temporal Block (TCN)
Input: X [B, F, H]
(batch size, input channels, sequence length)

Conv1d Layer 1
ReLU
Dropout
Conv1d Layer 2
ReLU
Dropout
Residual Connection

Output: Y [B, C_out, L]
----------------
repeated 4x
Output: [B, C4, H] -> [B, C4] (taking the last time step)


Validation:

Hyperparameter tuning was done with grid search, on 
param_grid = {
    'hidden_dim':   [64, 128],
    'dropout':      [0.2, 0.4],
    'lr':           [0.001, 0.0005],
    'weight_decay': [0.0, 0.0001],
    'batch_size':   [32, 64, 128, 256]
}

Sampled randomly 20 times. 

With nabor1 learning is quite unstable, however because of low batchsize persumably?? TODO:, the model better escapes local minima, so the best score of all time on the final leaderboard was obtained using these hyperparameters and trained on only train/val in 0.9:0.1 ratio compared to train/val/holdout with 0.8:0.1:0.1 ratio.

However the most stable set of hyperparameters with around 0.08 higher final mse, is nabor2.

The model was locally evaluated on nabor2 set of hyperparameters on a holdout set, giving
Holdout MSE: 9.4291 on 40 sequences (2080 timestamps, 160 predictions)
Leaderboard MSE (9.3670)