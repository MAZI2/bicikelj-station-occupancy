{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/matjeez/Library/Jupyter/runtime/kernel-v331e8e24bb8c98bea820a6bfa6304f49c7326b8ba.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/IS/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import holidays\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- Constants & Config ---\n",
    "HISTORY_LEN = 48\n",
    "PRED_HORIZON = 4\n",
    "K_NEIGHBORS = 2\n",
    "EMBED_DIM = 8\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYERS = 4\n",
    "LR = 0.0005\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT = 0.4\n",
    "EPOCHS = 100\n",
    "PATIENCE = 8\n",
    "BATCH_SIZE = 256\n",
    "VAL_FRAC = 0.2\n",
    "STRIDE = 1\n",
    "MODEL_PATH = \"tcn_model_final_with_stats.pt\"\n",
    "WEATHER_FEATURES = ['temperature_2m', 'precipitation', 'windspeed_10m', 'cloudcover']\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Dataset ---\n",
    "class SharedTCNDataset(Dataset):\n",
    "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon, weather_features, sample_indices):\n",
    "        self.samples = []\n",
    "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "        timestamps = pd.to_datetime(df['timestamp'])\n",
    "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "        month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
    "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "        slo_holidays = holidays.Slovenia()\n",
    "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "        weather_array = df[weather_features].values\n",
    "        time_feats = np.concatenate([\n",
    "            np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
    "                      month_sin, month_cos, is_weekend, is_holiday], axis=1),\n",
    "            weather_array\n",
    "        ], axis=1)\n",
    "        bikes = df[station_cols].values.astype(np.float32)\n",
    "        N = len(df)\n",
    "        for s_name in station_cols:\n",
    "            s_idx = self.station_to_idx[s_name]\n",
    "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
    "            series = bikes[:, [s_idx] + nn_idx]\n",
    "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
    "            for i in sample_indices:\n",
    "                x = full_feats[i - history_len:i]\n",
    "                y = bikes[i:i + pred_horizon, s_idx]\n",
    "                self.samples.append((x, y, s_idx))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, sid = self.samples[idx]\n",
    "        return (torch.tensor(x, dtype=torch.float32),\n",
    "                torch.tensor(y, dtype=torch.float32),\n",
    "                torch.tensor(sid, dtype=torch.long))\n",
    "\n",
    "# --- Model ---\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out[:, :, :-self.padding] if self.padding > 0 else out\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = out[:, :, :-self.padding] if self.padding > 0 else out\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
    "            out_ch = num_channels[i]\n",
    "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "    def forward(self, x, station_id):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        tcn_out = self.tcn(x)[:, :, -1]\n",
    "        emb = self.embedding(station_id)\n",
    "        combined = torch.cat([tcn_out, emb], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def load_and_clean_bikes(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    station_cols = df.columns[1:]\n",
    "    for col in station_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df[station_cols] = df[station_cols].ffill().bfill()\n",
    "    df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_localize(None)\n",
    "    return df, station_cols\n",
    "\n",
    "def load_weather(filename):\n",
    "    weather_df = pd.read_csv(filename, skiprows=2)\n",
    "    weather_df = weather_df.rename(columns={\n",
    "        'temperature_2m (Â°C)': 'temperature_2m',\n",
    "        'precipitation (mm)': 'precipitation',\n",
    "        'windspeed_10m (km/h)': 'windspeed_10m',\n",
    "        'cloudcover (%)': 'cloudcover'\n",
    "    })\n",
    "    weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "    return weather_df\n",
    "\n",
    "def merge_weather(df, weather_df):\n",
    "    return pd.merge(df, weather_df, left_on='timestamp', right_on='time', how='left')\n",
    "\n",
    "def calc_neighbors(meta_csv, k=K_NEIGHBORS):\n",
    "    meta = pd.read_csv(meta_csv)\n",
    "    coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
    "    station_names = meta['name'].tolist()\n",
    "    dists = haversine_distances(coords, coords) * 6371\n",
    "    neighbors = {}\n",
    "    for i, name in enumerate(station_names):\n",
    "        order = np.argsort(dists[i])\n",
    "        nn_idx = [j for j in order if j != i][:k]\n",
    "        neighbors[name] = [station_names[j] for j in nn_idx]\n",
    "    return neighbors\n",
    "\n",
    "def make_sample_indices(mask, history_len, pred_horizon, stride=1):\n",
    "    N = len(mask)\n",
    "    indices = []\n",
    "    for i in range(history_len, N - pred_horizon + 1, stride):\n",
    "        if mask[i - history_len:i + pred_horizon].all():\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "def compute_time_features(timestamps, slo_holidays=None):\n",
    "    hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "    hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "    dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "    dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "    month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "    month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
    "    is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "    if slo_holidays is None:\n",
    "        slo_holidays = holidays.Slovenia()\n",
    "    is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "    time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos, month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
    "    return time_feats\n",
    "\n",
    "# --- Train ---\n",
    "def train_main():\n",
    "    df, station_cols = load_and_clean_bikes(\"bicikelj_train.csv\")\n",
    "    weather_df = load_weather(\"weather_ljubljana.csv\")\n",
    "    df_merged = merge_weather(df, weather_df)\n",
    "    df_merged[WEATHER_FEATURES] = df_merged[WEATHER_FEATURES].ffill().bfill()\n",
    "    N = len(df_merged)\n",
    "\n",
    "    # Validation split (non-overlapping blocks)\n",
    "    BLOCK_SIZE = HISTORY_LEN + PRED_HORIZON\n",
    "    np.random.seed(42)\n",
    "    all_possible_starts = np.arange(0, N - BLOCK_SIZE + 1)\n",
    "    val_mask = np.zeros(N, dtype=bool)\n",
    "    val_starts = []\n",
    "    target_val_coverage = int(VAL_FRAC * N)\n",
    "    covered = 0\n",
    "    np.random.shuffle(all_possible_starts)\n",
    "    for start in all_possible_starts:\n",
    "        if val_mask[start:start + BLOCK_SIZE].any(): continue\n",
    "        val_mask[start:start + BLOCK_SIZE] = True\n",
    "        val_starts.append(start)\n",
    "        covered += BLOCK_SIZE\n",
    "        if covered >= target_val_coverage: break\n",
    "    train_mask = ~val_mask\n",
    "\n",
    "    train_indices = make_sample_indices(train_mask, HISTORY_LEN, PRED_HORIZON, stride=STRIDE)\n",
    "    val_indices = make_sample_indices(val_mask, HISTORY_LEN, PRED_HORIZON, stride=1)\n",
    "\n",
    "    # Normalization (train stats only)\n",
    "    station_means = df_merged.loc[train_mask, station_cols].mean()\n",
    "    station_stds  = df_merged.loc[train_mask, station_cols].std().replace(0, 1)\n",
    "    weather_means = df_merged.loc[train_mask, WEATHER_FEATURES].mean()\n",
    "    weather_stds  = df_merged.loc[train_mask, WEATHER_FEATURES].std().replace(0, 1)\n",
    "    df_merged[station_cols] = (df_merged[station_cols] - station_means) / station_stds\n",
    "    df_merged[WEATHER_FEATURES] = (df_merged[WEATHER_FEATURES] - weather_means) / weather_stds\n",
    "\n",
    "    # Neighbors\n",
    "    neighbors = calc_neighbors(\"bicikelj_metadata.csv\", K_NEIGHBORS)\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset = SharedTCNDataset(df_merged, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON, WEATHER_FEATURES, train_indices)\n",
    "    val_dataset = SharedTCNDataset(df_merged, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON, WEATHER_FEATURES, val_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
    "\n",
    "    print(f\"Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\")\n",
    "\n",
    "    # Model\n",
    "    input_size = 1 + K_NEIGHBORS + (8 + len(WEATHER_FEATURES))\n",
    "    model = TCN(input_size, PRED_HORIZON, [HIDDEN_DIM] * N_LAYERS, 3, DROPOUT,\n",
    "                num_stations=len(station_cols), embed_dim=EMBED_DIM).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb, sid in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb, sid), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, sid in val_loader:\n",
    "                xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
    "                val_loss += criterion(model(xb, sid), yb).item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Val Loss = {avg_val_loss:.4f}\")\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'station_means': station_means,\n",
    "        'station_stds': station_stds,\n",
    "        'weather_means': weather_means,\n",
    "        'weather_stds': weather_stds\n",
    "    }, MODEL_PATH)\n",
    "    print(f\"âœ… Saved model to '{MODEL_PATH}'\")\n",
    "\n",
    "# --- Predict ---\n",
    "def predict_main():\n",
    "    print(\"ðŸš² Prediction mode\")\n",
    "    # --- Load test and train stats for normalization ---\n",
    "    df, station_cols = load_and_clean_bikes(\"bicikelj_train.csv\")\n",
    "    weather_train_df = load_weather(\"weather_ljubljana.csv\")\n",
    "    df_merged = merge_weather(df, weather_train_df)\n",
    "    df_merged[WEATHER_FEATURES] = df_merged[WEATHER_FEATURES].ffill().bfill()\n",
    "    station_means = df_merged[station_cols].mean()\n",
    "    station_stds = df_merged[station_cols].std().replace(0, 1)\n",
    "    weather_means = df_merged[WEATHER_FEATURES].mean()\n",
    "    weather_stds = df_merged[WEATHER_FEATURES].std().replace(0, 1)\n",
    "    neighbors = calc_neighbors(\"bicikelj_metadata.csv\", K_NEIGHBORS)\n",
    "    name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "\n",
    "    # Load model and normalization\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    input_size = 1 + K_NEIGHBORS + (8 + len(WEATHER_FEATURES))\n",
    "    model = TCN(input_size, PRED_HORIZON, [HIDDEN_DIM] * N_LAYERS, 3, DROPOUT,\n",
    "                num_stations=len(station_cols), embed_dim=EMBED_DIM).to(DEVICE)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.eval()\n",
    "    # Use train stats saved with model, if present:\n",
    "    station_means = checkpoint.get('station_means', station_means)\n",
    "    station_stds = checkpoint.get('station_stds', station_stds)\n",
    "    weather_means = checkpoint.get('weather_means', weather_means)\n",
    "    weather_stds = checkpoint.get('weather_stds', weather_stds)\n",
    "\n",
    "    # --- Prepare test set ---\n",
    "    test_df = pd.read_csv(\"bicikelj_test.csv\")\n",
    "    test_feats = test_df[station_cols].values.astype(np.float32)\n",
    "    timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
    "    weather_test_df = load_weather(\"weather_ljubljana_test.csv\")\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp']).dt.tz_localize(None)\n",
    "    test_df_merged = merge_weather(test_df, weather_test_df)\n",
    "    test_df_merged[WEATHER_FEATURES] = test_df_merged[WEATHER_FEATURES].ffill().bfill()\n",
    "    weather_feats = test_df_merged[WEATHER_FEATURES].values.astype(np.float32)\n",
    "    time_feats = compute_time_features(timestamps)\n",
    "    test_feats_norm = (test_feats - station_means.values) / station_stds.values\n",
    "    weather_feats_norm = (weather_feats - weather_means.values) / weather_stds.values\n",
    "\n",
    "    pred_matrix = np.full_like(test_feats, np.nan)\n",
    "    with torch.no_grad():\n",
    "        for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
    "            # Only predict for rows that are missing all stations (== test target region)\n",
    "            if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
    "                for station in station_cols:\n",
    "                    s_idx = name_to_idx[station]\n",
    "                    nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
    "                    seq = []\n",
    "                    for t in range(i - HISTORY_LEN, i):\n",
    "                        row = [test_feats_norm[t, s_idx]]\n",
    "                        row += [test_feats_norm[t, j] for j in nn_idx]\n",
    "                        row += list(time_feats[t])\n",
    "                        row += list(weather_feats_norm[t])\n",
    "                        seq.append(row)\n",
    "                    seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
    "                    sid_tensor = torch.tensor([s_idx], dtype=torch.long, device=DEVICE)\n",
    "                    pred_norm = model(seq, sid_tensor).cpu().numpy().flatten()\n",
    "                    pred = pred_norm * station_stds[s_idx] + station_means[s_idx]\n",
    "                    for j in range(PRED_HORIZON):\n",
    "                        pred_matrix[i + j, s_idx] = pred[j]\n",
    "    # --- Save predictions ---\n",
    "    pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
    "    pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
    "    rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
    "    pred_df_filtered = pred_df[rows_to_output].copy()\n",
    "    pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn_weather.csv\", index=False)\n",
    "    print(\"âœ… Saved predictions to 'bicikelj_test_predictions_tcn_weather.csv'\")\n",
    "\n",
    "# --- Main Entrypoint ---\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train', action='store_true', help='Train mode: trains and saves model')\n",
    "    args = parser.parse_args()\n",
    "    if args.train:\n",
    "        train_main()\n",
    "    else:\n",
    "        predict_main()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
