{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TCN Bicikelj final training + test prediction with speedups ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "import random\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "HISTORY_LEN = 48\n",
    "PRED_HORIZON = 4\n",
    "K_NEIGHBORS = 2\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EMBED_DIM = 8\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYERS = 3\n",
    "LR = 0.0005\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT = 0.2\n",
    "EPOCHS = 50\n",
    "PATIENCE = 8\n",
    "BATCH_SIZE = 128  # increased safely\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_csv(\"bicikelj_train.csv\")\n",
    "meta = pd.read_csv(\"bicikelj_metadata.csv\")\n",
    "station_cols = df.columns[1:]\n",
    "\n",
    "# Clean and fill\n",
    "for col in station_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df[station_cols] = df[station_cols].ffill().bfill()\n",
    "df = df.dropna(subset=station_cols, how='all').reset_index(drop=True)\n",
    "\n",
    "# Station normalization\n",
    "station_means = df[station_cols].mean()\n",
    "station_stds = df[station_cols].std().replace(0, 1)\n",
    "df_norm = df.copy()\n",
    "df_norm[station_cols] = (df[station_cols] - station_means) / station_stds\n",
    "\n",
    "# Neighbors\n",
    "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
    "station_names = meta['name'].tolist()\n",
    "dists = haversine_distances(coords, coords) * 6371\n",
    "neighbors = {}\n",
    "for i, name in enumerate(station_names):\n",
    "    order = np.argsort(dists[i])\n",
    "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
    "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
    "\n",
    "# --- Dataset ---\n",
    "class SharedTCNDataset(Dataset):\n",
    "    def __init__(self, df, station_cols, neighbors, history_len, pred_horizon):\n",
    "        self.samples = []\n",
    "        self.station_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "        timestamps = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "        hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "        hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "        dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "        dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "        month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "        month_cos = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "        is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "        slo_holidays = holidays.Slovenia()\n",
    "        is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "        time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
    "                               month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
    "\n",
    "        bikes = df[station_cols].values.astype(np.float32)\n",
    "        N = len(df)\n",
    "\n",
    "        for s_name in station_cols:\n",
    "            s_idx = self.station_to_idx[s_name]\n",
    "            nn_idx = [self.station_to_idx[nn] for nn in neighbors[s_name]]\n",
    "            series = bikes[:, [s_idx] + nn_idx]\n",
    "            full_feats = np.concatenate([series, time_feats], axis=1)\n",
    "\n",
    "            for i in range(history_len, N - pred_horizon + 1):\n",
    "                x = full_feats[i - history_len:i]\n",
    "                y = bikes[i:i + pred_horizon, s_idx]\n",
    "                self.samples.append((x, y, s_idx))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, sid = self.samples[idx]\n",
    "        return (torch.tensor(x, dtype=torch.float32),\n",
    "                torch.tensor(y, dtype=torch.float32),\n",
    "                torch.tensor(sid, dtype=torch.long))\n",
    "\n",
    "# --- TCN Block ---\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out[:, :, :-self.padding]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = out[:, :, :-self.padding]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
    "            out_ch = num_channels[i]\n",
    "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, station_id):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        tcn_out = self.tcn(x)[:, :, -1]\n",
    "        emb = self.embedding(station_id)\n",
    "        combined = torch.cat([tcn_out, emb], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# --- Create Dataset and split ---\n",
    "dataset = SharedTCNDataset(df_norm, station_cols, neighbors, HISTORY_LEN, PRED_HORIZON)\n",
    "\n",
    "N = len(dataset)\n",
    "indices = list(range(N))\n",
    "random.shuffle(indices)\n",
    "\n",
    "val_size = int(0.1 * N)  # 10% for val\n",
    "train_size = N - val_size\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "train_set = Subset(dataset, train_indices)\n",
    "val_set = Subset(dataset, val_indices)\n",
    "\n",
    "# --- DataLoaders with speedups ---\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
    "\n",
    "# --- Model ---\n",
    "model = TCN(input_size=1 + K_NEIGHBORS + 8,\n",
    "            output_size=PRED_HORIZON,\n",
    "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
    "            kernel_size=3,\n",
    "            dropout=DROPOUT,\n",
    "            num_stations=len(station_cols),\n",
    "            embed_dim=EMBED_DIM).to(DEVICE)\n",
    "\n",
    "# --- Optimizer and Loss ---\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- Training loop ---\n",
    "best_loss = float('inf')\n",
    "best_state = None\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb, sid in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb, sid), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, sid in val_loader:\n",
    "            xb, yb, sid = xb.to(DEVICE), yb.to(DEVICE), sid.to(DEVICE)\n",
    "            val_loss += criterion(model(xb, sid), yb).item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- Early stopping on val loss ---\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        best_state = model.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# --- Save best model ---\n",
    "model.load_state_dict(best_state)\n",
    "torch.save(model.state_dict(), \"tcn_model_final.pt\")\n",
    "print(\"✅ Saved model to 'tcn_model_final.pt'\")\n",
    "\n",
    "# --- Predict on test set ---\n",
    "# (keep your current test loop as is → no changes needed there)\n",
    "\n",
    "# --- Predict on bicikelj_test.csv ---\n",
    "test_df = pd.read_csv(\"bicikelj_test.csv\")\n",
    "test_feats = test_df[station_cols].values.astype(np.float32)\n",
    "timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
    "\n",
    "# Time features\n",
    "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
    "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "slo_holidays = holidays.Slovenia()\n",
    "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "\n",
    "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
    "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
    "\n",
    "name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "\n",
    "# Load model for inference\n",
    "model.eval()\n",
    "\n",
    "pred_matrix = np.full_like(test_feats, np.nan)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
    "        if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
    "            for station in station_cols:\n",
    "                s_idx = name_to_idx[station]\n",
    "                nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
    "\n",
    "                seq = []\n",
    "                for t in range(i - HISTORY_LEN, i):\n",
    "                    row = [test_feats[t, s_idx]]\n",
    "                    row += [test_feats[t, j] for j in nn_idx]\n",
    "                    row += list(time_feats[t])\n",
    "                    seq.append(row)\n",
    "                seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "                pred_norm = model(seq, torch.tensor([s_idx], dtype=torch.long, device=DEVICE)).cpu().numpy().flatten()\n",
    "                pred = pred_norm * station_stds[station] + station_means[station]\n",
    "\n",
    "                for j in range(PRED_HORIZON):\n",
    "                    pred_matrix[i + j, s_idx] = pred[j]\n",
    "\n",
    "# Save predictions\n",
    "pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
    "pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
    "rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
    "pred_df_filtered = pred_df[rows_to_output].copy()\n",
    "pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn.csv\", index=False)\n",
    "print(\"✅ Saved predictions to 'bicikelj_test_predictions_tcn.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict only the unknown rows in bicikelj_test.csv using final TCN model ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import holidays\n",
    "\n",
    "# --- Constants ---\n",
    "HISTORY_LEN = 48\n",
    "PRED_HORIZON = 4\n",
    "K_NEIGHBORS = 2\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EMBED_DIM = 8\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# --- Load metadata ---\n",
    "meta = pd.read_csv(\"bicikelj_metadata.csv\")\n",
    "station_cols = pd.read_csv(\"bicikelj_test.csv\").columns[1:]\n",
    "station_names = meta['name'].tolist()\n",
    "\n",
    "# --- Neighbors ---\n",
    "coords = np.deg2rad(meta[['latitude', 'longitude']].values)\n",
    "dists = haversine_distances(coords, coords) * 6371\n",
    "neighbors = {}\n",
    "for i, name in enumerate(station_names):\n",
    "    order = np.argsort(dists[i])\n",
    "    nn_idx = [j for j in order if j != i][:K_NEIGHBORS]\n",
    "    neighbors[name] = [station_names[j] for j in nn_idx]\n",
    "\n",
    "# --- Load training stats for normalization ---\n",
    "df_train = pd.read_csv(\"bicikelj_train.csv\")\n",
    "station_means = df_train[station_cols].mean()\n",
    "station_stds = df_train[station_cols].std().replace(0, 1)\n",
    "\n",
    "# --- TCN Model definition ---\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=self.padding, dilation=dilation)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out[:, :, :-self.padding]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = out[:, :, :-self.padding]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, num_stations, embed_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_ch = input_size if i == 0 else num_channels[i - 1]\n",
    "            out_ch = num_channels[i]\n",
    "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, dilation_size, dropout)]\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.embedding = nn.Embedding(num_stations, embed_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_channels[-1] + embed_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, station_id):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        tcn_out = self.tcn(x)[:, :, -1]\n",
    "        emb = self.embedding(station_id)\n",
    "        combined = torch.cat([tcn_out, emb], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# --- Load model ---\n",
    "model = TCN(input_size=1 + K_NEIGHBORS + 8,\n",
    "            output_size=PRED_HORIZON,\n",
    "            num_channels=[HIDDEN_DIM] * N_LAYERS,\n",
    "            kernel_size=3,\n",
    "            dropout=DROPOUT,\n",
    "            num_stations=len(station_cols),\n",
    "            embed_dim=EMBED_DIM).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"tcn_model_final.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# --- Load test set ---\n",
    "test_df = pd.read_csv(\"bicikelj_test.csv\")\n",
    "test_feats = test_df[station_cols].values.astype(np.float32)\n",
    "timestamps = pd.to_datetime(test_df[\"timestamp\"])\n",
    "\n",
    "# --- Time features ---\n",
    "hour_sin = np.sin(2 * np.pi * timestamps.dt.hour / 24)\n",
    "hour_cos = np.cos(2 * np.pi * timestamps.dt.hour / 24)\n",
    "dow_sin = np.sin(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "dow_cos = np.cos(2 * np.pi * timestamps.dt.dayofweek / 7)\n",
    "month_sin = np.sin(2 * np.pi * timestamps.dt.month / 12)\n",
    "month_cos = np.cos(2 * np.pi * timestamps.dt.month / 12)\n",
    "is_weekend = (timestamps.dt.dayofweek >= 5).astype(float)\n",
    "slo_holidays = holidays.Slovenia()\n",
    "is_holiday = timestamps.dt.date.astype(str).isin([str(d) for d in slo_holidays]).astype(float)\n",
    "\n",
    "time_feats = np.stack([hour_sin, hour_cos, dow_sin, dow_cos,\n",
    "                       month_sin, month_cos, is_weekend, is_holiday], axis=1)\n",
    "\n",
    "# --- Normalize test_feats using training stats ---\n",
    "test_feats_norm = (test_feats - station_means.values) / station_stds.values\n",
    "\n",
    "# --- Predict ---\n",
    "name_to_idx = {name: i for i, name in enumerate(station_cols)}\n",
    "\n",
    "pred_matrix = np.full_like(test_feats, np.nan)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(HISTORY_LEN, len(test_df) - PRED_HORIZON + 1):\n",
    "        if np.isnan(test_feats[i:i + PRED_HORIZON]).all(axis=0).all():\n",
    "            for station in station_cols:\n",
    "                s_idx = name_to_idx[station]\n",
    "                nn_idx = [name_to_idx[nn] for nn in neighbors[station]]\n",
    "\n",
    "                seq = []\n",
    "                for t in range(i - HISTORY_LEN, i):\n",
    "                    row = [test_feats_norm[t, s_idx]]\n",
    "                    row += [test_feats_norm[t, j] for j in nn_idx]\n",
    "                    row += list(time_feats[t])\n",
    "                    seq.append(row)\n",
    "\n",
    "                seq = torch.tensor([seq], dtype=torch.float32).to(DEVICE)\n",
    "                sid_tensor = torch.tensor([s_idx], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "                pred_norm = model(seq, sid_tensor).cpu().numpy().flatten()\n",
    "                pred = pred_norm * station_stds[station] + station_means[station]\n",
    "\n",
    "                for j in range(PRED_HORIZON):\n",
    "                    pred_matrix[i + j, s_idx] = pred[j]\n",
    "\n",
    "# --- Save predictions ---\n",
    "pred_df = pd.DataFrame(pred_matrix, columns=station_cols)\n",
    "pred_df.insert(0, \"timestamp\", test_df[\"timestamp\"])\n",
    "\n",
    "rows_to_output = test_df[station_cols].isna().all(axis=1)\n",
    "pred_df_filtered = pred_df[rows_to_output].copy()\n",
    "\n",
    "pred_df_filtered.to_csv(\"bicikelj_test_predictions_tcn.csv\", index=False)\n",
    "print(\"✅ Saved predictions to 'bicikelj_test_predictions_tcn.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
